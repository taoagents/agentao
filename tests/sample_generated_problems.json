[
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_asyncio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_anyio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "1. Adapt the async test framework to support both asyncio and anyio simultaneously in a single test case. This involves integrating configurations or decorators that allow a test case to use either or both asynchronous libraries based on its requirements.",
        "dynamic_checklist": [
            "Ensure compatibility between asyncio and anyio in a single test case.",
            "Identify any conflicting behaviors between asyncio and anyio and address them appropriately.",
            "Validate that both asyncio and anyio tasks can run concurrently without errors."
        ],
        "context_files": [
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n",
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n"
        ],
        "model_stats": {
            "input_tokens": 574,
            "output_tokens": 959,
            "cost": 0.011025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_asyncio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_anyio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "2. Create a utility function that runs asynchronous test cases using both `pytest_asyncio` and `pytest_anyio` decorators to verify that the test functions perform identically under different event loops. Implement this function to be callable within a test suite.",
        "dynamic_checklist": [
            "Ensure the utility function applies both asyncio and anyio decorators to test cases effectively.",
            "Verify that the results are consistent between the two libraries when the same test is executed.",
            "Handle potential differences in exception handling between the libraries."
        ],
        "context_files": [
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n",
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n"
        ],
        "model_stats": {
            "input_tokens": 574,
            "output_tokens": 959,
            "cost": 0.011025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_asyncio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_anyio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "3. Introduce a custom pytest plugin that dynamically selects the most efficient asynchronous library (`asyncio` or `anyio`) to execute a given test based on preconfigured conditions or runtime environment variables.",
        "dynamic_checklist": [
            "Create configuration options for the custom plugin to select between asyncio and anyio.",
            "Ensure the plugin can be registered and used seamlessly within existing pytest test suites.",
            "Implement logging to provide insights into which library was chosen for a test case and why."
        ],
        "context_files": [
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n",
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n"
        ],
        "model_stats": {
            "input_tokens": 574,
            "output_tokens": 959,
            "cost": 0.011025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_asyncio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_anyio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "4. Design and implement a mechanism to allow test cases written for `pytest_asyncio_integration.py` to be ported or converted to work with `pytest_anyio_integration.py`, and vice versa, without manually altering each test.",
        "dynamic_checklist": [
            "Develop a script or tool to automate the conversion process between asyncio and anyio test cases.",
            "Ensure the conversions preserve the original test logic and assertions.",
            "Validate the functionality of converted tests by running a sample suite."
        ],
        "context_files": [
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n",
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n"
        ],
        "model_stats": {
            "input_tokens": 574,
            "output_tokens": 959,
            "cost": 0.011025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_asyncio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_anyio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "5. Refactor the existing test functions in `pytest_asyncio_integration.py` and `pytest_anyio_integration.py` to include a benchmarking feature that measures and reports the execution time of tests run under different async libraries.",
        "dynamic_checklist": [
            "Implement timing and reporting mechanisms within the test functions.",
            "Present the benchmark results in a clear and accessible format, such as a console output or a report file.",
            "Ensure minimal overhead is introduced to the test execution time due to benchmarking."
        ],
        "context_files": [
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n",
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n"
        ],
        "model_stats": {
            "input_tokens": 574,
            "output_tokens": 959,
            "cost": 0.011025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_asyncio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_anyio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "6. Develop a compatibility matrix utility within the test suite to automatically verify and report on the compatibility of test cases with different async libraries and their respective versions.",
        "dynamic_checklist": [
            "Create the framework for the compatibility matrix, including criteria for success or failure.",
            "Integrate the matrix into the test execution pipeline, providing results post-run.",
            "Include a reporting mechanism to easily identify incompatible test cases and their respective issues."
        ],
        "context_files": [
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n",
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n"
        ],
        "model_stats": {
            "input_tokens": 574,
            "output_tokens": 959,
            "cost": 0.011025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_asyncio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_anyio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "7. Enhance the codebase to support conditional test case execution based on the availability of the asyncio or anyio library, allowing the same test suite to run in environments that may only support one library.",
        "dynamic_checklist": [
            "Implement detection mechanisms to assess the availability of asyncio or anyio in the environment.",
            "Develop conditional decorators or test wrappers to execute tests selectively based on availability.",
            "Test thoroughly in environments where only one of the libraries is supported."
        ],
        "context_files": [
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n",
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n"
        ],
        "model_stats": {
            "input_tokens": 574,
            "output_tokens": 959,
            "cost": 0.011025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_asyncio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_anyio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "8. Implement a logging mechanism for both `pytest_asyncio_integration.py` and `pytest_anyio_integration.py` to capture detailed logs during test execution, aiding in debugging and providing insights into the async operations being tested.",
        "dynamic_checklist": [
            "Set up a logging framework that works consistently across both asyncio and anyio based tests.",
            "Ensure logs capture critical test execution details, including errors and task states.",
            "Allow log levels to be configurable to support different verbosity levels."
        ],
        "context_files": [
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n",
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n"
        ],
        "model_stats": {
            "input_tokens": 574,
            "output_tokens": 959,
            "cost": 0.011025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_asyncio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_anyio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "9. Integrate a feature within both `pytest_asyncio_integration.py` and `pytest_anyio_integration.py` files that captures and outputs statistics about the test case coverage for async operations in the codebase.",
        "dynamic_checklist": [
            "Implement a mechanism to track and report on the coverage of async functions by test cases.",
            "Ensure the feature can integrate with existing coverage tools used in the project, if any.",
            "Provide a user-friendly output format for the coverage statistics."
        ],
        "context_files": [
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n",
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n"
        ],
        "model_stats": {
            "input_tokens": 574,
            "output_tokens": 959,
            "cost": 0.011025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_asyncio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/pytest/testing/plugins_integration/pytest_anyio_integration.py\n```python3\n# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "10. Develop a feature to handle and display cross-library test dependencies, focusing on potential fan-out or fan-in dependencies between test functions utilizing `pytest_asyncio` and `pytest_anyio` decorators.",
        "dynamic_checklist": [
            "Analyze dependencies between test functions across the libraries and address dependency resolutions.",
            "Implement a display feature that effectively communicates dependency relationships and potential issues.",
            "Ensure that the feature supports scalability as new test cases are added."
        ],
        "context_files": [
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport asyncio\n\nimport pytest\n\n\n@pytest.mark.asyncio\nasync def test_sleep():\n    await asyncio.sleep(0)\n",
            "# mypy: allow-untyped-defs\nfrom __future__ import annotations\n\nimport anyio\n\nimport pytest\n\n\n@pytest.mark.anyio\nasync def test_sleep():\n    await anyio.sleep(0)\n"
        ],
        "model_stats": {
            "input_tokens": 574,
            "output_tokens": 959,
            "cost": 0.011025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Implement a new test suite to validate the integration of the color mapping between Continuous and Nominal scales in seaborn. The test suite should verify that color transitions correctly between different scale types when visualizing numeric and categorical data on the same axis.",
        "dynamic_checklist": [
            "Ensure tests cover both linear and logarithmic scales for numeric data.",
            "Verify that color mapping respects the order of categories provided by Nominal scales.",
            "Test with different color palettes including default, named, and custom palettes.",
            "Check for edge cases where color mappings may fail, such as empty categories or NaN values.",
            "Ensure compatibility with both matplotlib and pandas."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1136,
            "cost": 0.0427025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Develop a feature that allows customization of tick placement for both Continuous and Temporal scales. The feature should permit users to specify their own tick locations or use date-specific tick locators in the context of Temporal scales.",
        "dynamic_checklist": [
            "Allow user customization for tick placement using fixed locations and intervals.",
            "Support custom Locators for date ticks using `mpl.dates.YearLocator` or `mpl.dates.MonthLocator`.",
            "Test if custom ticks integrate properly with existing `PseudoAxis` tests.",
            "Ensure tick labels correspond correctly with user-defined locations.",
            "Handle edge cases where user-defined ticks exceed data limits."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1136,
            "cost": 0.0427025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Create a new function to support dynamic visualization updates for alpha values in plots based on a user-defined range. The function should dynamically adjust alpha transparency for data points on both Continuous and Boolean scales according to the plot's state.",
        "dynamic_checklist": [
            "Develop tests that simulate dynamic update scenarios for both scales.",
            "Ensure function integrates with `Alpha` class to modify transparency effectively.",
            "Validate that the function adapts changes in data, maintaining alpha range integrity.",
            "Check compatibility with interactive matplotlib features.",
            "Test boundary conditions by varying alpha range values."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1136,
            "cost": 0.0427025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Enable the `Fill` property to support hybrid data types in test scenarios. You must ensure that `Fill` can handle mixed data sets (e.g., nominal and numeric within the same test case) while preserving logical fill behavior in visual plots.",
        "dynamic_checklist": [
            "Ensure tests consider both categorical and numerical data in a single `Fill` test case.",
            "Validate fill pattern logic for mixed datasets, maintaining Boolean integrity.",
            "Test with different palette dictionaries to ensure consistent fill mapping.",
            "Check that errors are raised when unsupported data combinations occur.",
            "Document test cases thoroughly to provide clarity on logic handling."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1136,
            "cost": 0.0427025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Enhance the `IntervalProperty` testing suite to account for transformed data using power and logarithmic transformations. The tests should evaluate the `Continuous` interval mappings after such transformations.",
        "dynamic_checklist": [
            "Create tests for both power and logarithmic transformed scales using `IntervalProperty`.",
            "Ensure correct mapping of intervals for transformed data, especially for edge cases.",
            "Validate that incorrect transformation specifications raise appropriate errors.",
            "Integrate into existing `TestContinuous` to maintain consistency across test suites.",
            "Ensure that test coverage includes multiple transformations and their parameters."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1136,
            "cost": 0.0427025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Develop a function to automatically adjust the styling of plot markers in PointSize property value mappings, based on data magnitude and distribution within plots. The function should provide visual differentiation of data points for better interpretability.",
        "dynamic_checklist": [
            "Implement logic to vary marker size dynamically using the `PointSize` mapping.",
            "Ensure marker adjustments complement Continuous and Nominal scale values.",
            "Test the function across datasets with varying sizes and distributions.",
            "Verify that visual changes improve interpretability, without affecting data integrity.",
            "Ensure function integration does not break existing marker tests."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1136,
            "cost": 0.0427025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Introduce a mechanism to handle missing data within the `Coordinate` and `Nominal` classes. Develop a comprehensive test suite to ensure the robustness and reliability of plots that involve incomplete datasets, focusing on proper labeling and scaling handling.",
        "dynamic_checklist": [
            "Develop tests that simulate scenarios with various patterns of missing data.",
            "Ensure the mechanism maintains nominal scale order and data coherence.",
            "Test labeling handling for missing data across categorical and temporal plots.",
            "Verify that warnings or errors are raised appropriately for unsupported data entries.",
            "Document all related test cases and their expected outcomes for clarity."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1136,
            "cost": 0.0427025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Implement support for sequence-based markers in `TestMarker`, allowing the specification of complex and custom path sequences. This should extend the existing functionality to handle more sophisticated data point representations.",
        "dynamic_checklist": [
            "Develop new tests to validate support for custom sequence-based markers.",
            "Ensure functionality works seamlessly with existing `MarkerStyle` instances.",
            "Test with different sequence complexities, including nested sequences.",
            "Check that sequences translate correctly into expected visual representations.",
            "Guarantee backward compatibility with simpler marker styles."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1136,
            "cost": 0.0427025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Create a utility that automates the palette selection for Boolean scales based on data distribution diversity, providing a method to select the most informative and visually distinct palettes automatically.",
        "dynamic_checklist": [
            "Develop a logic to analyze data distribution and select appropriate palette automatically.",
            "Ensure utility integrates with `Boolean` scale to enhance visual contrast.",
            "Test automation with various dataset complexities for reliable palette selection.",
            "Assess impact on interpretability of visualizations comparing auto and manual settings.",
            "Verify that default palettes serve as a fallback when data does not present diversity."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1136,
            "cost": 0.0427025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Design an enhanced plotting feature for Temporal scale that supports multi-format time aggregation. Users should be able to visualize data in multiple time units (e.g., hours, days, months) dynamically within a single plot interface leveraging existing Temporal functionalities.",
        "dynamic_checklist": [
            "Support various time aggregation levels dynamically within the plot.",
            "Ensure integration with `Temporal` properties to handle multiple time formats.",
            "Test feature's flexibility with datasets varying in time granularity.",
            "Ensure consistent labeling and scaling when switching between time formats.",
            "Add extensive tests for edge cases involving mixed or incomplete time data."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1136,
            "cost": 0.0427025
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/subplots.py\n```python3\nfrom __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/plot.py\n```python3\n\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Integrate a new feature in the Seaborn plotting API to support customizing the order of subplots based on a user-defined function. This involves modifying the current subplot creation methods to accept and correctly interpret this custom ordering function while ensuring compatibility with current faceting and pairing functionality. The implementation must handle axis sharing and layout configuration appropriately following the user's custom order specification.",
        "dynamic_checklist": [
            "Ensure the maintainability of custom ordering by adhering to existing API design patterns.",
            "Verify that the custom ordering logic is compatible with current faceting and pairing functionalities.",
            "Implement test cases for various scenarios of custom ordering.",
            "Ensure appropriate axis sharing configurations are maintained post custom ordering.",
            "Document the new feature in the Seaborn API documentation."
        ],
        "context_files": [
            "from __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n",
            "\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n"
        ],
        "model_stats": {
            "input_tokens": 17693,
            "output_tokens": 1200,
            "cost": 0.0562325
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/subplots.py\n```python3\nfrom __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/plot.py\n```python3\n\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Develop support for persistent subplot aspect ratios across different facet and pair grid configurations. This requires introducing a parameter in the subplot API to control aspect ratios while maintaining the flexibility of current grid dimensionality and wrapping features. The solution should not interfere with existing layout and scale implementations.",
        "dynamic_checklist": [
            "Introduce a mechanism to set persistent subplot aspect ratios.",
            "Ensure compatibility with existing grid dimension and wrapping configurations.",
            "Implement tests for various grid configurations with different aspect ratios.",
            "Document the use of aspect ratios in conjunction with other Seaborn subplot features.",
            "Modify existing scale or layout methods if required to support aspect ratio persistence."
        ],
        "context_files": [
            "from __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n",
            "\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n"
        ],
        "model_stats": {
            "input_tokens": 17693,
            "output_tokens": 1200,
            "cost": 0.0562325
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/subplots.py\n```python3\nfrom __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/plot.py\n```python3\n\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Add functionality to the `PlotConfig` or `Subplots` classes to allow the detection and handling of overlapping axis labels. The implementation should dynamically adjust subplot spacing or rotate axis labels to optimize label visibility without disrupting the overall layout or figure size settings.",
        "dynamic_checklist": [
            "Develop algorithms for detecting label overlap on both axes.",
            "Implement dynamic adjustment of subplot spacing or rotation of axis labels.",
            "Ensure the solution maintains overall figure size settings.",
            "Test the feature across various plot configurations to ensure robustness.",
            "Update documentation with guidelines on how to use this feature."
        ],
        "context_files": [
            "from __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n",
            "\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n"
        ],
        "model_stats": {
            "input_tokens": 17693,
            "output_tokens": 1200,
            "cost": 0.0562325
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/subplots.py\n```python3\nfrom __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/plot.py\n```python3\n\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Create a detailed logging system for the plotting operations in Seaborn that provides insights into subplot creation, grid computations, and layout adjustments. This logging system should uniformly capture and output diagnostic information to help users optimize their plotting configurations.",
        "dynamic_checklist": [
            "Define logging levels to capture different granularity of information.",
            "Integrate logging calls into significant computational steps within the plotting subsystem.",
            "Ensure the logging system does not negatively impact plotting performance.",
            "Provide configuration options for users to enable or disable logging.",
            "Document how to use and interpret the logging outputs effectively."
        ],
        "context_files": [
            "from __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n",
            "\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n"
        ],
        "model_stats": {
            "input_tokens": 17693,
            "output_tokens": 1200,
            "cost": 0.0562325
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/subplots.py\n```python3\nfrom __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/plot.py\n```python3\n\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Enable support for subfigure plots within the current framework by extending the `Subplots` class to handle `SubFigure` instances. The implementation should allow subplots to be organized within predefined subfigure partitions, facilitating complex multi-panel plotting within the same figure.",
        "dynamic_checklist": [
            "Ensure that the logic for handling `SubFigure` is integrated seamlessly with existing plotting operations.",
            "Test layout and axis configuration for figures with multiple subfigures.",
            "Verify the compatibility of subfigure plots with existing scale and theme configurations.",
            "Document examples and edge cases of using subfigures in plots.",
            "Ensure backward compatibility with plots not using subfigures."
        ],
        "context_files": [
            "from __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n",
            "\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n"
        ],
        "model_stats": {
            "input_tokens": 17693,
            "output_tokens": 1200,
            "cost": 0.0562325
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/subplots.py\n```python3\nfrom __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/plot.py\n```python3\n\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Extend the axis sharing functionality to include optional axis hiding for specific subplot rows or columns, enhancing visual clarity by omitting redundant axes in highly faceted plots. The solution should maintain coherence with existing share configurations and plot configurations.",
        "dynamic_checklist": [
            "Implement a mechanism to specify axis hiding for designated rows or columns.",
            "Ensure the coherence of hidden axis states with shared axis configurations.",
            "Test axis hiding through a wide range of subplot configurations.",
            "Provide user documentation detailing the axis hiding feature and use-cases.",
            "Verify that axis hiding integration does not introduce bugs in other shared axes contexts."
        ],
        "context_files": [
            "from __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n",
            "\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n"
        ],
        "model_stats": {
            "input_tokens": 17693,
            "output_tokens": 1200,
            "cost": 0.0562325
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/subplots.py\n```python3\nfrom __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/plot.py\n```python3\n\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Introduce a feature that allows for automated addition of data annotations to subplots based on specific conditions set by the user within the `Plot` API. This feature will enhance the interpretability of plots with relevant data-driven annotations.",
        "dynamic_checklist": [
            "Design an API interface for specifying annotation conditions and styling.",
            "Integrate annotation logic into the existing plot rendering pipeline.",
            "Ensure that annotations do not disrupt existing scales or data representations.",
            "Create test cases to validate annotation placement and conditions.",
            "Document usage examples in the Seaborn library guides and tutorials."
        ],
        "context_files": [
            "from __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n",
            "\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n"
        ],
        "model_stats": {
            "input_tokens": 17693,
            "output_tokens": 1200,
            "cost": 0.0562325
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/subplots.py\n```python3\nfrom __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/plot.py\n```python3\n\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Add support for interactive subplot selection within the `Plot` class, enabling users to click on subplots for more detailed exploration or customization. This requires integrating interactive features compatible with static images produced by Seaborn.",
        "dynamic_checklist": [
            "Design a user interface for selecting subplots using mouse events.",
            "Ensure compatibility with different rendering backends used by Matplotlib and Seaborn.",
            "Enable interactive functionalities to trigger additional methods or events upon selection.",
            "Create detailed tests to validate the functionality across operating systems and browsers.",
            "Update the user guide with instructions and FAQs on interactive subplot usage."
        ],
        "context_files": [
            "from __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n",
            "\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n"
        ],
        "model_stats": {
            "input_tokens": 17693,
            "output_tokens": 1200,
            "cost": 0.0562325
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/subplots.py\n```python3\nfrom __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/plot.py\n```python3\n\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Implement a mechanism to synchronize color palettes across a pair plot grid while respecting individual plot data properties and ensuring distinctive plot visuals. The synchronization should intelligently handle varied data distributions and scales across subplots.",
        "dynamic_checklist": [
            "Enable inter-plot that respects individual data properties yet maintains cohesive aesthetics.",
            "Develop algorithms that adjust and synchronize color palettes dynamically.",
            "Test color synchronization with multiple data distributions and grid configurations.",
            "Provide documentation on how synchronized color palettes can be adjusted or overridden by users.",
            "Maintain robustness and efficiency in rendering when synchronizing colors."
        ],
        "context_files": [
            "from __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n",
            "\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n"
        ],
        "model_stats": {
            "input_tokens": 17693,
            "output_tokens": 1200,
            "cost": 0.0562325
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/subplots.py\n```python3\nfrom __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/seaborn/_core/plot.py\n```python3\n\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Enhance the Facet and PairSpec functionalities to optimize grid layouts for high-density data visualization, particularly in contexts with extremely large numbers of subplots. The solution must maintain responsive performance while ensuring data visibility and clarity.",
        "dynamic_checklist": [
            "Investigate rendering optimizations that maintain reasonable performance at scale.",
            "Implement and test layout algorithms that optimize for high subplot counts without visual data loss.",
            "Ensure that dynamic grid adjustments do not reposition or resize subplots unexpectedly.",
            "Add testing for high-density visualization scenarios to ensure robustness.",
            "Include user documentation explaining limitations and best practices for high-density faceted plots."
        ],
        "context_files": [
            "from __future__ import annotations\nfrom collections.abc import Generator\n\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.axes import Axes\nfrom matplotlib.figure import Figure\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:  # TODO move to seaborn._core.typing?\n    from seaborn._core.plot import FacetSpec, PairSpec\n    from matplotlib.figure import SubFigure\n\n\nclass Subplots:\n    \"\"\"\n    Interface for creating and using matplotlib subplots based on seaborn parameters.\n\n    Parameters\n    ----------\n    subplot_spec : dict\n        Keyword args for :meth:`matplotlib.figure.Figure.subplots`.\n    facet_spec : dict\n        Parameters that control subplot faceting.\n    pair_spec : dict\n        Parameters that control subplot pairing.\n    data : PlotData\n        Data used to define figure setup.\n\n    \"\"\"\n    def __init__(\n        self,\n        subplot_spec: dict,  # TODO define as TypedDict\n        facet_spec: FacetSpec,\n        pair_spec: PairSpec,\n    ):\n\n        self.subplot_spec = subplot_spec\n\n        self._check_dimension_uniqueness(facet_spec, pair_spec)\n        self._determine_grid_dimensions(facet_spec, pair_spec)\n        self._handle_wrapping(facet_spec, pair_spec)\n        self._determine_axis_sharing(pair_spec)\n\n    def _check_dimension_uniqueness(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Reject specs that pair and facet on (or wrap to) same figure dimension.\"\"\"\n        err = None\n\n        facet_vars = facet_spec.get(\"variables\", {})\n\n        if facet_spec.get(\"wrap\") and {\"col\", \"row\"} <= set(facet_vars):\n            err = \"Cannot wrap facets when specifying both `col` and `row`.\"\n        elif (\n            pair_spec.get(\"wrap\")\n            and pair_spec.get(\"cross\", True)\n            and len(pair_spec.get(\"structure\", {}).get(\"x\", [])) > 1\n            and len(pair_spec.get(\"structure\", {}).get(\"y\", [])) > 1\n        ):\n            err = \"Cannot wrap subplots when pairing on both `x` and `y`.\"\n\n        collisions = {\"x\": [\"columns\", \"rows\"], \"y\": [\"rows\", \"columns\"]}\n        for pair_axis, (multi_dim, wrap_dim) in collisions.items():\n            if pair_axis not in pair_spec.get(\"structure\", {}):\n                continue\n            elif multi_dim[:3] in facet_vars:\n                err = f\"Cannot facet the {multi_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and facet_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {wrap_dim} while pairing on `{pair_axis}``.\"\n            elif wrap_dim[:3] in facet_vars and pair_spec.get(\"wrap\"):\n                err = f\"Cannot wrap the {multi_dim} while faceting the {wrap_dim}.\"\n\n        if err is not None:\n            raise RuntimeError(err)  # TODO what err class? Define PlotSpecError?\n\n    def _determine_grid_dimensions(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Parse faceting and pairing information to define figure structure.\"\"\"\n        self.grid_dimensions: dict[str, list] = {}\n        for dim, axis in zip([\"col\", \"row\"], [\"x\", \"y\"]):\n\n            facet_vars = facet_spec.get(\"variables\", {})\n            if dim in facet_vars:\n                self.grid_dimensions[dim] = facet_spec[\"structure\"][dim]\n            elif axis in pair_spec.get(\"structure\", {}):\n                self.grid_dimensions[dim] = [\n                    None for _ in pair_spec.get(\"structure\", {})[axis]\n                ]\n            else:\n                self.grid_dimensions[dim] = [None]\n\n            self.subplot_spec[f\"n{dim}s\"] = len(self.grid_dimensions[dim])\n\n        if not pair_spec.get(\"cross\", True):\n            self.subplot_spec[\"nrows\"] = 1\n\n        self.n_subplots = self.subplot_spec[\"ncols\"] * self.subplot_spec[\"nrows\"]\n\n    def _handle_wrapping(\n        self, facet_spec: FacetSpec, pair_spec: PairSpec\n    ) -> None:\n        \"\"\"Update figure structure parameters based on facet/pair wrapping.\"\"\"\n        self.wrap = wrap = facet_spec.get(\"wrap\") or pair_spec.get(\"wrap\")\n        if not wrap:\n            return\n\n        wrap_dim = \"row\" if self.subplot_spec[\"nrows\"] > 1 else \"col\"\n        flow_dim = {\"row\": \"col\", \"col\": \"row\"}[wrap_dim]\n        n_subplots = self.subplot_spec[f\"n{wrap_dim}s\"]\n        flow = int(np.ceil(n_subplots / wrap))\n\n        if wrap < self.subplot_spec[f\"n{wrap_dim}s\"]:\n            self.subplot_spec[f\"n{wrap_dim}s\"] = wrap\n        self.subplot_spec[f\"n{flow_dim}s\"] = flow\n        self.n_subplots = n_subplots\n        self.wrap_dim = wrap_dim\n\n    def _determine_axis_sharing(self, pair_spec: PairSpec) -> None:\n        \"\"\"Update subplot spec with default or specified axis sharing parameters.\"\"\"\n        axis_to_dim = {\"x\": \"col\", \"y\": \"row\"}\n        key: str\n        val: str | bool\n        for axis in \"xy\":\n            key = f\"share{axis}\"\n            # Always use user-specified value, if present\n            if key not in self.subplot_spec:\n                if axis in pair_spec.get(\"structure\", {}):\n                    # Paired axes are shared along one dimension by default\n                    if self.wrap is None and pair_spec.get(\"cross\", True):\n                        val = axis_to_dim[axis]\n                    else:\n                        val = False\n                else:\n                    # This will pick up faceted plots, as well as single subplot\n                    # figures, where the value doesn't really matter\n                    val = True\n                self.subplot_spec[key] = val\n\n    def init_figure(\n        self,\n        pair_spec: PairSpec,\n        pyplot: bool = False,\n        figure_kws: dict | None = None,\n        target: Axes | Figure | SubFigure | None = None,\n    ) -> Figure:\n        \"\"\"Initialize matplotlib objects and add seaborn-relevant metadata.\"\"\"\n        # TODO reduce need to pass pair_spec here?\n\n        if figure_kws is None:\n            figure_kws = {}\n\n        if isinstance(target, mpl.axes.Axes):\n\n            if max(self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]) > 1:\n                err = \" \".join([\n                    \"Cannot create multiple subplots after calling `Plot.on` with\",\n                    f\"a {mpl.axes.Axes} object.\",\n                    f\" You may want to use a {mpl.figure.SubFigure} instead.\",\n                ])\n                raise RuntimeError(err)\n\n            self._subplot_list = [{\n                \"ax\": target,\n                \"left\": True,\n                \"right\": True,\n                \"top\": True,\n                \"bottom\": True,\n                \"col\": None,\n                \"row\": None,\n                \"x\": \"x\",\n                \"y\": \"y\",\n            }]\n            self._figure = target.figure\n            return self._figure\n\n        elif isinstance(target, mpl.figure.SubFigure):\n            figure = target.figure\n        elif isinstance(target, mpl.figure.Figure):\n            figure = target\n        else:\n            if pyplot:\n                figure = plt.figure(**figure_kws)\n            else:\n                figure = mpl.figure.Figure(**figure_kws)\n            target = figure\n        self._figure = figure\n\n        axs = target.subplots(**self.subplot_spec, squeeze=False)\n\n        if self.wrap:\n            # Remove unused Axes and flatten the rest into a (2D) vector\n            axs_flat = axs.ravel({\"col\": \"C\", \"row\": \"F\"}[self.wrap_dim])\n            axs, extra = np.split(axs_flat, [self.n_subplots])\n            for ax in extra:\n                ax.remove()\n            if self.wrap_dim == \"col\":\n                axs = axs[np.newaxis, :]\n            else:\n                axs = axs[:, np.newaxis]\n\n        # Get i, j coordinates for each Axes object\n        # Note that i, j are with respect to faceting/pairing,\n        # not the subplot grid itself, (which only matters in the case of wrapping).\n        iter_axs: np.ndenumerate | zip\n        if not pair_spec.get(\"cross\", True):\n            indices = np.arange(self.n_subplots)\n            iter_axs = zip(zip(indices, indices), axs.flat)\n        else:\n            iter_axs = np.ndenumerate(axs)\n\n        self._subplot_list = []\n        for (i, j), ax in iter_axs:\n\n            info = {\"ax\": ax}\n\n            nrows, ncols = self.subplot_spec[\"nrows\"], self.subplot_spec[\"ncols\"]\n            if not self.wrap:\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = (j + 1) % ncols == 0\n                info[\"top\"] = i == 0\n                info[\"bottom\"] = i == nrows - 1\n            elif self.wrap_dim == \"col\":\n                info[\"left\"] = j % ncols == 0\n                info[\"right\"] = ((j + 1) % ncols == 0) or ((j + 1) == self.n_subplots)\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= (self.n_subplots - ncols)\n            elif self.wrap_dim == \"row\":\n                info[\"left\"] = i < nrows\n                info[\"right\"] = i >= self.n_subplots - nrows\n                info[\"top\"] = i % nrows == 0\n                info[\"bottom\"] = ((i + 1) % nrows == 0) or ((i + 1) == self.n_subplots)\n\n            if not pair_spec.get(\"cross\", True):\n                info[\"top\"] = j < ncols\n                info[\"bottom\"] = j >= self.n_subplots - ncols\n\n            for dim in [\"row\", \"col\"]:\n                idx = {\"row\": i, \"col\": j}[dim]\n                info[dim] = self.grid_dimensions[dim][idx]\n\n            for axis in \"xy\":\n\n                idx = {\"x\": j, \"y\": i}[axis]\n                if axis in pair_spec.get(\"structure\", {}):\n                    key = f\"{axis}{idx}\"\n                else:\n                    key = axis\n                info[axis] = key\n\n            self._subplot_list.append(info)\n\n        return figure\n\n    def __iter__(self) -> Generator[dict, None, None]:  # TODO TypedDict?\n        \"\"\"Yield each subplot dictionary with Axes object and metadata.\"\"\"\n        yield from self._subplot_list\n\n    def __len__(self) -> int:\n        \"\"\"Return the number of subplots in this figure.\"\"\"\n        return len(self._subplot_list)\n",
            "\"\"\"The classes for specifying and compiling a declarative visualization.\"\"\"\nfrom __future__ import annotations\n\nimport io\nimport os\nimport re\nimport inspect\nimport itertools\nimport textwrap\nfrom contextlib import contextmanager\nfrom collections import abc\nfrom collections.abc import Callable, Generator, Mapping\nfrom typing import Any, List, Literal, Optional, cast\nfrom xml.etree import ElementTree\n\nfrom cycler import cycler\nimport pandas as pd\nfrom pandas import DataFrame, Series, Index\nimport matplotlib as mpl\nfrom matplotlib.axes import Axes\nfrom matplotlib.artist import Artist\nfrom matplotlib.figure import Figure\nimport numpy as np\nfrom PIL import Image\n\nfrom seaborn._marks.base import Mark\nfrom seaborn._stats.base import Stat\nfrom seaborn._core.data import PlotData\nfrom seaborn._core.moves import Move\nfrom seaborn._core.scales import Scale\nfrom seaborn._core.subplots import Subplots\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._core.properties import PROPERTIES, Property\nfrom seaborn._core.typing import (\n    DataSource,\n    VariableSpec,\n    VariableSpecList,\n    OrderSpec,\n    Default,\n)\nfrom seaborn._core.exceptions import PlotSpecError\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._compat import get_layout_engine, set_layout_engine\nfrom seaborn.utils import _version_predates\nfrom seaborn.rcmod import axes_style, plotting_context\nfrom seaborn.palettes import color_palette\n\nfrom typing import TYPE_CHECKING, TypedDict\nif TYPE_CHECKING:\n    from matplotlib.figure import SubFigure\n\n\ndefault = Default()\n\n\n# ---- Definitions for internal specs ---------------------------------------------- #\n\n\nclass Layer(TypedDict, total=False):\n\n    mark: Mark  # TODO allow list?\n    stat: Stat | None  # TODO allow list?\n    move: Move | list[Move] | None\n    data: PlotData\n    source: DataSource\n    vars: dict[str, VariableSpec]\n    orient: str\n    legend: bool\n    label: str | None\n\n\nclass FacetSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    wrap: int | None\n\n\nclass PairSpec(TypedDict, total=False):\n\n    variables: dict[str, VariableSpec]\n    structure: dict[str, list[str]]\n    cross: bool\n    wrap: int | None\n\n\n# --- Local helpers ---------------------------------------------------------------- #\n\n\n@contextmanager\ndef theme_context(params: dict[str, Any]) -> Generator:\n    \"\"\"Temporarily modify specifc matplotlib rcParams.\"\"\"\n    orig_params = {k: mpl.rcParams[k] for k in params}\n    color_codes = \"bgrmyck\"\n    nice_colors = [*color_palette(\"deep6\"), (.15, .15, .15)]\n    orig_colors = [mpl.colors.colorConverter.colors[x] for x in color_codes]\n    # TODO how to allow this to reflect the color cycle when relevant?\n    try:\n        mpl.rcParams.update(params)\n        for (code, color) in zip(color_codes, nice_colors):\n            mpl.colors.colorConverter.colors[code] = color\n        yield\n    finally:\n        mpl.rcParams.update(orig_params)\n        for (code, color) in zip(color_codes, orig_colors):\n            mpl.colors.colorConverter.colors[code] = color\n\n\ndef build_plot_signature(cls):\n    \"\"\"\n    Decorator function for giving Plot a useful signature.\n\n    Currently this mostly saves us some duplicated typing, but we would\n    like eventually to have a way of registering new semantic properties,\n    at which point dynamic signature generation would become more important.\n\n    \"\"\"\n    sig = inspect.signature(cls)\n    params = [\n        inspect.Parameter(\"args\", inspect.Parameter.VAR_POSITIONAL),\n        inspect.Parameter(\"data\", inspect.Parameter.KEYWORD_ONLY, default=None)\n    ]\n    params.extend([\n        inspect.Parameter(name, inspect.Parameter.KEYWORD_ONLY, default=None)\n        for name in PROPERTIES\n    ])\n    new_sig = sig.replace(parameters=params)\n    cls.__signature__ = new_sig\n\n    known_properties = textwrap.fill(\n        \", \".join([f\"|{p}|\" for p in PROPERTIES]),\n        width=78, subsequent_indent=\" \" * 8,\n    )\n\n    if cls.__doc__ is not None:  # support python -OO mode\n        cls.__doc__ = cls.__doc__.format(known_properties=known_properties)\n\n    return cls\n\n\n# ---- Plot configuration ---------------------------------------------------------- #\n\n\nclass ThemeConfig(mpl.RcParams):\n    \"\"\"\n    Configuration object for the Plot.theme, using matplotlib rc parameters.\n    \"\"\"\n    THEME_GROUPS = [\n        \"axes\", \"figure\", \"font\", \"grid\", \"hatch\", \"legend\", \"lines\",\n        \"mathtext\", \"markers\", \"patch\", \"savefig\", \"scatter\",\n        \"xaxis\", \"xtick\", \"yaxis\", \"ytick\",\n    ]\n\n    def __init__(self):\n        super().__init__()\n        self.reset()\n\n    @property\n    def _default(self) -> dict[str, Any]:\n\n        return {\n            **self._filter_params(mpl.rcParamsDefault),\n            **axes_style(\"darkgrid\"),\n            **plotting_context(\"notebook\"),\n            \"axes.prop_cycle\": cycler(\"color\", color_palette(\"deep\")),\n        }\n\n    def reset(self) -> None:\n        \"\"\"Update the theme dictionary with seaborn's default values.\"\"\"\n        self.update(self._default)\n\n    def update(self, other: dict[str, Any] | None = None, /, **kwds):\n        \"\"\"Update the theme with a dictionary or keyword arguments of rc parameters.\"\"\"\n        if other is not None:\n            theme = self._filter_params(other)\n        else:\n            theme = {}\n        theme.update(kwds)\n        super().update(theme)\n\n    def _filter_params(self, params: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Restruct to thematic rc params.\"\"\"\n        return {\n            k: v for k, v in params.items()\n            if any(k.startswith(p) for p in self.THEME_GROUPS)\n        }\n\n    def _html_table(self, params: dict[str, Any]) -> list[str]:\n\n        lines = [\"<table>\"]\n        for k, v in params.items():\n            row = f\"<tr><td>{k}:</td><td style='text-align:left'>{v!r}</td></tr>\"\n            lines.append(row)\n        lines.append(\"</table>\")\n        return lines\n\n    def _repr_html_(self) -> str:\n\n        repr = [\n            \"<div style='height: 300px'>\",\n            \"<div style='border-style: inset; border-width: 2px'>\",\n            *self._html_table(self),\n            \"</div>\",\n            \"</div>\",\n        ]\n        return \"\\n\".join(repr)\n\n\nclass DisplayConfig(TypedDict):\n    \"\"\"Configuration for IPython's rich display hooks.\"\"\"\n    format: Literal[\"png\", \"svg\"]\n    scaling: float\n    hidpi: bool\n\n\nclass PlotConfig:\n    \"\"\"Configuration for default behavior / appearance of class:`Plot` instances.\"\"\"\n    def __init__(self):\n\n        self._theme = ThemeConfig()\n        self._display = {\"format\": \"png\", \"scaling\": .85, \"hidpi\": True}\n\n    @property\n    def theme(self) -> dict[str, Any]:\n        \"\"\"\n        Dictionary of base theme parameters for :class:`Plot`.\n\n        Keys and values correspond to matplotlib rc params, as documented here:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        \"\"\"\n        return self._theme\n\n    @property\n    def display(self) -> DisplayConfig:\n        \"\"\"\n        Dictionary of parameters for rich display in Jupyter notebook.\n\n        Valid parameters:\n\n        - format (\"png\" or \"svg\"): Image format to produce\n        - scaling (float): Relative scaling of embedded image\n        - hidpi (bool): When True, double the DPI while preserving the size\n\n        \"\"\"\n        return self._display\n\n\n# ---- The main interface for declarative plotting --------------------------------- #\n\n\n@build_plot_signature\nclass Plot:\n    \"\"\"\n    An interface for declaratively specifying statistical graphics.\n\n    Plots are constructed by initializing this class and adding one or more\n    layers, comprising a `Mark` and optional `Stat` or `Move`.  Additionally,\n    faceting variables or variable pairings may be defined to divide the space\n    into multiple subplots. The mappings from data values to visual properties\n    can be parametrized using scales, although the plot will try to infer good\n    defaults when scales are not explicitly defined.\n\n    The constructor accepts a data source (a :class:`pandas.DataFrame` or\n    dictionary with columnar values) and variable assignments. Variables can be\n    passed as keys to the data source or directly as data vectors.  If multiple\n    data-containing objects are provided, they will be index-aligned.\n\n    The data source and variables defined in the constructor will be used for\n    all layers in the plot, unless overridden or disabled when adding a layer.\n\n    The following variables can be defined in the constructor:\n        {known_properties}\n\n    The `data`, `x`, and `y` variables can be passed as positional arguments or\n    using keywords. Whether the first positional argument is interpreted as a\n    data source or `x` variable depends on its type.\n\n    The methods of this class return a copy of the instance; use chaining to\n    build up a plot through multiple calls. Methods can be called in any order.\n\n    Most methods only add information to the plot spec; no actual processing\n    happens until the plot is shown or saved. It is also possible to compile\n    the plot without rendering it to access the lower-level representation.\n\n    \"\"\"\n    config = PlotConfig()\n\n    _data: PlotData\n    _layers: list[Layer]\n\n    _scales: dict[str, Scale]\n    _shares: dict[str, bool | str]\n    _limits: dict[str, tuple[Any, Any]]\n    _labels: dict[str, str | Callable[[str], str]]\n    _theme: dict[str, Any]\n\n    _facet_spec: FacetSpec\n    _pair_spec: PairSpec\n\n    _figure_spec: dict[str, Any]\n    _subplot_spec: dict[str, Any]\n    _layout_spec: dict[str, Any]\n\n    def __init__(\n        self,\n        *args: DataSource | VariableSpec,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ):\n\n        if args:\n            data, variables = self._resolve_positionals(args, data, variables)\n\n        unknown = [x for x in variables if x not in PROPERTIES]\n        if unknown:\n            err = f\"Plot() got unexpected keyword argument(s): {', '.join(unknown)}\"\n            raise TypeError(err)\n\n        self._data = PlotData(data, variables)\n\n        self._layers = []\n\n        self._scales = {}\n        self._shares = {}\n        self._limits = {}\n        self._labels = {}\n        self._theme = {}\n\n        self._facet_spec = {}\n        self._pair_spec = {}\n\n        self._figure_spec = {}\n        self._subplot_spec = {}\n        self._layout_spec = {}\n\n        self._target = None\n\n    def _resolve_positionals(\n        self,\n        args: tuple[DataSource | VariableSpec, ...],\n        data: DataSource,\n        variables: dict[str, VariableSpec],\n    ) -> tuple[DataSource, dict[str, VariableSpec]]:\n        \"\"\"Handle positional arguments, which may contain data / x / y.\"\"\"\n        if len(args) > 3:\n            err = \"Plot() accepts no more than 3 positional arguments (data, x, y).\"\n            raise TypeError(err)\n\n        if (\n            isinstance(args[0], (abc.Mapping, pd.DataFrame))\n            or hasattr(args[0], \"__dataframe__\")\n        ):\n            if data is not None:\n                raise TypeError(\"`data` given by both name and position.\")\n            data, args = args[0], args[1:]\n\n        if len(args) == 2:\n            x, y = args\n        elif len(args) == 1:\n            x, y = *args, None\n        else:\n            x = y = None\n\n        for name, var in zip(\"yx\", (y, x)):\n            if var is not None:\n                if name in variables:\n                    raise TypeError(f\"`{name}` given by both name and position.\")\n                # Keep coordinates at the front of the variables dict\n                # Cast type because we know this isn't a DataSource at this point\n                variables = {name: cast(VariableSpec, var), **variables}\n\n        return data, variables\n\n    def __add__(self, other):\n\n        if isinstance(other, Mark) or isinstance(other, Stat):\n            raise TypeError(\"Sorry, this isn't ggplot! Perhaps try Plot.add?\")\n\n        other_type = other.__class__.__name__\n        raise TypeError(f\"Unsupported operand type(s) for +: 'Plot' and '{other_type}\")\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n        return self.plot()._repr_png_()\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n        return self.plot()._repr_svg_()\n\n    def _clone(self) -> Plot:\n        \"\"\"Generate a new object with the same information as the current spec.\"\"\"\n        new = Plot()\n\n        # TODO any way to enforce that data does not get mutated?\n        new._data = self._data\n\n        new._layers.extend(self._layers)\n\n        new._scales.update(self._scales)\n        new._shares.update(self._shares)\n        new._limits.update(self._limits)\n        new._labels.update(self._labels)\n        new._theme.update(self._theme)\n\n        new._facet_spec.update(self._facet_spec)\n        new._pair_spec.update(self._pair_spec)\n\n        new._figure_spec.update(self._figure_spec)\n        new._subplot_spec.update(self._subplot_spec)\n        new._layout_spec.update(self._layout_spec)\n\n        new._target = self._target\n\n        return new\n\n    def _theme_with_defaults(self) -> dict[str, Any]:\n\n        theme = self.config.theme.copy()\n        theme.update(self._theme)\n        return theme\n\n    @property\n    def _variables(self) -> list[str]:\n\n        variables = (\n            list(self._data.frame)\n            + list(self._pair_spec.get(\"variables\", []))\n            + list(self._facet_spec.get(\"variables\", []))\n        )\n        for layer in self._layers:\n            variables.extend(v for v in layer[\"vars\"] if v not in variables)\n\n        # Coerce to str in return to appease mypy; we know these will only\n        # ever be strings but I don't think we can type a DataFrame that way yet\n        return [str(v) for v in variables]\n\n    def on(self, target: Axes | SubFigure | Figure) -> Plot:\n        \"\"\"\n        Provide existing Matplotlib figure or axes for drawing the plot.\n\n        When using this method, you will also need to explicitly call a method that\n        triggers compilation, such as :meth:`Plot.show` or :meth:`Plot.save`. If you\n        want to postprocess using matplotlib, you'd need to call :meth:`Plot.plot`\n        first to compile the plot without rendering it.\n\n        Parameters\n        ----------\n        target : Axes, SubFigure, or Figure\n            Matplotlib object to use. Passing :class:`matplotlib.axes.Axes` will add\n            artists without otherwise modifying the figure. Otherwise, subplots will be\n            created within the space of the given :class:`matplotlib.figure.Figure` or\n            :class:`matplotlib.figure.SubFigure`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.on.rst\n\n        \"\"\"\n        accepted_types: tuple  # Allow tuple of various length\n        accepted_types = (\n            mpl.axes.Axes, mpl.figure.SubFigure, mpl.figure.Figure\n        )\n        accepted_types_str = (\n            f\"{mpl.axes.Axes}, {mpl.figure.SubFigure}, or {mpl.figure.Figure}\"\n        )\n\n        if not isinstance(target, accepted_types):\n            err = (\n                f\"The `Plot.on` target must be an instance of {accepted_types_str}. \"\n                f\"You passed an instance of {target.__class__} instead.\"\n            )\n            raise TypeError(err)\n\n        new = self._clone()\n        new._target = target\n\n        return new\n\n    def add(\n        self,\n        mark: Mark,\n        *transforms: Stat | Move,\n        orient: str | None = None,\n        legend: bool = True,\n        label: str | None = None,\n        data: DataSource = None,\n        **variables: VariableSpec,\n    ) -> Plot:\n        \"\"\"\n        Specify a layer of the visualization in terms of mark and data transform(s).\n\n        This is the main method for specifying how the data should be visualized.\n        It can be called multiple times with different arguments to define\n        a plot with multiple layers.\n\n        Parameters\n        ----------\n        mark : :class:`Mark`\n            The visual representation of the data to use in this layer.\n        transforms : :class:`Stat` or :class:`Move`\n            Objects representing transforms to be applied before plotting the data.\n            Currently, at most one :class:`Stat` can be used, and it\n            must be passed first. This constraint will be relaxed in the future.\n        orient : \"x\", \"y\", \"v\", or \"h\"\n            The orientation of the mark, which also affects how transforms are computed.\n            Typically corresponds to the axis that defines groups for aggregation.\n            The \"v\" (vertical) and \"h\" (horizontal) options are synonyms for \"x\" / \"y\",\n            but may be more intuitive with some marks. When not provided, an\n            orientation will be inferred from characteristics of the data and scales.\n        legend : bool\n            Option to suppress the mark/mappings for this layer from the legend.\n        label : str\n            A label to use for the layer in the legend, independent of any mappings.\n        data : DataFrame or dict\n            Data source to override the global source provided in the constructor.\n        variables : data vectors or identifiers\n            Additional layer-specific variables, including variables that will be\n            passed directly to the transforms without scaling.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.add.rst\n\n        \"\"\"\n        if not isinstance(mark, Mark):\n            msg = f\"mark must be a Mark instance, not {type(mark)!r}.\"\n            raise TypeError(msg)\n\n        # TODO This API for transforms was a late decision, and previously Plot.add\n        # accepted 0 or 1 Stat instances and 0, 1, or a list of Move instances.\n        # It will take some work to refactor the internals so that Stat and Move are\n        # treated identically, and until then well need to \"unpack\" the transforms\n        # here and enforce limitations on the order / types.\n\n        stat: Optional[Stat]\n        move: Optional[List[Move]]\n        error = False\n        if not transforms:\n            stat, move = None, None\n        elif isinstance(transforms[0], Stat):\n            stat = transforms[0]\n            move = [m for m in transforms[1:] if isinstance(m, Move)]\n            error = len(move) != len(transforms) - 1\n        else:\n            stat = None\n            move = [m for m in transforms if isinstance(m, Move)]\n            error = len(move) != len(transforms)\n\n        if error:\n            msg = \" \".join([\n                \"Transforms must have at most one Stat type (in the first position),\",\n                \"and all others must be a Move type. Given transform type(s):\",\n                \", \".join(str(type(t).__name__) for t in transforms) + \".\"\n            ])\n            raise TypeError(msg)\n\n        new = self._clone()\n        new._layers.append({\n            \"mark\": mark,\n            \"stat\": stat,\n            \"move\": move,\n            # TODO it doesn't work to supply scalars to variables, but it should\n            \"vars\": variables,\n            \"source\": data,\n            \"legend\": legend,\n            \"label\": label,\n            \"orient\": {\"v\": \"x\", \"h\": \"y\"}.get(orient, orient),  # type: ignore\n        })\n\n        return new\n\n    def pair(\n        self,\n        x: VariableSpecList = None,\n        y: VariableSpecList = None,\n        wrap: int | None = None,\n        cross: bool = True,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots by pairing multiple `x` and/or `y` variables.\n\n        Parameters\n        ----------\n        x, y : sequence(s) of data vectors or identifiers\n            Variables that will define the grid of subplots.\n        wrap : int\n            When using only `x` or `y`, \"wrap\" subplots across a two-dimensional grid\n            with this many columns (when using `x`) or rows (when using `y`).\n        cross : bool\n            When False, zip the `x` and `y` lists such that the first subplot gets the\n            first pair, the second gets the second pair, etc. Otherwise, create a\n            two-dimensional grid from the cartesian product of the lists.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.pair.rst\n\n        \"\"\"\n        # TODO Add transpose= arg, which would then draw pair(y=[...]) across rows\n        # This may also be possible by setting `wrap=1`, but is that too unobvious?\n        # TODO PairGrid features not currently implemented: diagonals, corner\n\n        pair_spec: PairSpec = {}\n\n        axes = {\"x\": [] if x is None else x, \"y\": [] if y is None else y}\n        for axis, arg in axes.items():\n            if isinstance(arg, (str, int)):\n                err = f\"You must pass a sequence of variable keys to `{axis}`\"\n                raise TypeError(err)\n\n        pair_spec[\"variables\"] = {}\n        pair_spec[\"structure\"] = {}\n\n        for axis in \"xy\":\n            keys = []\n            for i, col in enumerate(axes[axis]):\n                key = f\"{axis}{i}\"\n                keys.append(key)\n                pair_spec[\"variables\"][key] = col\n\n            if keys:\n                pair_spec[\"structure\"][axis] = keys\n\n        if not cross and len(axes[\"x\"]) != len(axes[\"y\"]):\n            err = \"Lengths of the `x` and `y` lists must match with cross=False\"\n            raise ValueError(err)\n\n        pair_spec[\"cross\"] = cross\n        pair_spec[\"wrap\"] = wrap\n\n        new = self._clone()\n        new._pair_spec.update(pair_spec)\n        return new\n\n    def facet(\n        self,\n        col: VariableSpec = None,\n        row: VariableSpec = None,\n        order: OrderSpec | dict[str, OrderSpec] = None,\n        wrap: int | None = None,\n    ) -> Plot:\n        \"\"\"\n        Produce subplots with conditional subsets of the data.\n\n        Parameters\n        ----------\n        col, row : data vectors or identifiers\n            Variables used to define subsets along the columns and/or rows of the grid.\n            Can be references to the global data source passed in the constructor.\n        order : list of strings, or dict with dimensional keys\n            Define the order of the faceting variables.\n        wrap : int\n            When using only `col` or `row`, wrap subplots across a two-dimensional\n            grid with this many subplots on the faceting dimension.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.facet.rst\n\n        \"\"\"\n        variables: dict[str, VariableSpec] = {}\n        if col is not None:\n            variables[\"col\"] = col\n        if row is not None:\n            variables[\"row\"] = row\n\n        structure = {}\n        if isinstance(order, dict):\n            for dim in [\"col\", \"row\"]:\n                dim_order = order.get(dim)\n                if dim_order is not None:\n                    structure[dim] = list(dim_order)\n        elif order is not None:\n            if col is not None and row is not None:\n                err = \" \".join([\n                    \"When faceting on both col= and row=, passing `order` as a list\"\n                    \"is ambiguous. Use a dict with 'col' and/or 'row' keys instead.\"\n                ])\n                raise RuntimeError(err)\n            elif col is not None:\n                structure[\"col\"] = list(order)\n            elif row is not None:\n                structure[\"row\"] = list(order)\n\n        spec: FacetSpec = {\n            \"variables\": variables,\n            \"structure\": structure,\n            \"wrap\": wrap,\n        }\n\n        new = self._clone()\n        new._facet_spec.update(spec)\n\n        return new\n\n    # TODO def twin()?\n\n    def scale(self, **scales: Scale) -> Plot:\n        \"\"\"\n        Specify mappings from data units to visual properties.\n\n        Keywords correspond to variables defined in the plot, including coordinate\n        variables (`x`, `y`) and semantic variables (`color`, `pointsize`, etc.).\n\n        A number of \"magic\" arguments are accepted, including:\n            - The name of a transform (e.g., `\"log\"`, `\"sqrt\"`)\n            - The name of a palette (e.g., `\"viridis\"`, `\"muted\"`)\n            - A tuple of values, defining the output range (e.g. `(1, 5)`)\n            - A dict, implying a :class:`Nominal` scale (e.g. `{\"a\": .2, \"b\": .5}`)\n            - A list of values, implying a :class:`Nominal` scale (e.g. `[\"b\", \"r\"]`)\n\n        For more explicit control, pass a scale spec object such as :class:`Continuous`\n        or :class:`Nominal`. Or pass `None` to use an \"identity\" scale, which treats\n        data values as literally encoding visual properties.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.scale.rst\n\n        \"\"\"\n        new = self._clone()\n        new._scales.update(scales)\n        return new\n\n    def share(self, **shares: bool | str) -> Plot:\n        \"\"\"\n        Control sharing of axis limits and ticks across subplots.\n\n        Keywords correspond to variables defined in the plot, and values can be\n        boolean (to share across all subplots), or one of \"row\" or \"col\" (to share\n        more selectively across one dimension of a grid).\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.share.rst\n\n        \"\"\"\n        new = self._clone()\n        new._shares.update(shares)\n        return new\n\n    def limit(self, **limits: tuple[Any, Any]) -> Plot:\n        \"\"\"\n        Control the range of visible data.\n\n        Keywords correspond to variables defined in the plot, and values are a\n        `(min, max)` tuple (where either can be `None` to leave unset).\n\n        Limits apply only to the axis; data outside the visible range are\n        still used for any stat transforms and added to the plot.\n\n        Behavior for non-coordinate variables is currently undefined.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.limit.rst\n\n        \"\"\"\n        new = self._clone()\n        new._limits.update(limits)\n        return new\n\n    def label(\n        self, *,\n        title: str | None = None,\n        legend: str | None = None,\n        **variables: str | Callable[[str], str]\n    ) -> Plot:\n        \"\"\"\n        Control the labels and titles for axes, legends, and subplots.\n\n        Additional keywords correspond to variables defined in the plot.\n        Values can be one of the following types:\n\n        - string (used literally; pass \"\" to clear the default label)\n        - function (called on the default label)\n\n        For coordinate variables, the value sets the axis label.\n        For semantic variables, the value sets the legend title.\n        For faceting variables, `title=` modifies the subplot-specific label,\n        while `col=` and/or `row=` add a label for the faceting variable.\n\n        When using a single subplot, `title=` sets its title.\n\n        The `legend=` parameter sets the title for the \"layer\" legend\n        (i.e., when using `label` in :meth:`Plot.add`).\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.label.rst\n\n\n        \"\"\"\n        new = self._clone()\n        if title is not None:\n            new._labels[\"title\"] = title\n        if legend is not None:\n            new._labels[\"legend\"] = legend\n        new._labels.update(variables)\n        return new\n\n    def layout(\n        self,\n        *,\n        size: tuple[float, float] | Default = default,\n        engine: str | None | Default = default,\n        extent: tuple[float, float, float, float] | Default = default,\n    ) -> Plot:\n        \"\"\"\n        Control the figure size and layout.\n\n        .. note::\n\n            Default figure sizes and the API for specifying the figure size are subject\n            to change in future \"experimental\" releases of the objects API. The default\n            layout engine may also change.\n\n        Parameters\n        ----------\n        size : (width, height)\n            Size of the resulting figure, in inches. Size is inclusive of legend when\n            using pyplot, but not otherwise.\n        engine : {{\"tight\", \"constrained\", \"none\"}}\n            Name of method for automatically adjusting the layout to remove overlap.\n            The default depends on whether :meth:`Plot.on` is used.\n        extent : (left, bottom, right, top)\n            Boundaries of the plot layout, in fractions of the figure size. Takes\n            effect through the layout engine; exact results will vary across engines.\n            Note: the extent includes axis decorations when using a layout engine,\n            but it is exclusive of them when `engine=\"none\"`.\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.layout.rst\n\n        \"\"\"\n        # TODO add an \"auto\" mode for figsize that roughly scales with the rcParams\n        # figsize (so that works), but expands to prevent subplots from being squished\n        # Also should we have height=, aspect=, exclusive with figsize? Or working\n        # with figsize when only one is defined?\n\n        new = self._clone()\n\n        if size is not default:\n            new._figure_spec[\"figsize\"] = size\n        if engine is not default:\n            new._layout_spec[\"engine\"] = engine\n        if extent is not default:\n            new._layout_spec[\"extent\"] = extent\n\n        return new\n\n    # TODO def legend (ugh)\n\n    def theme(self, config: Mapping[str, Any], /) -> Plot:\n        \"\"\"\n        Control the appearance of elements in the plot.\n\n        .. note::\n\n            The API for customizing plot appearance is not yet finalized.\n            Currently, the only valid argument is a dict of matplotlib rc parameters.\n            (This dict must be passed as a positional argument.)\n\n            It is likely that this method will be enhanced in future releases.\n\n        Matplotlib rc parameters are documented on the following page:\n        https://matplotlib.org/stable/tutorials/introductory/customizing.html\n\n        Examples\n        --------\n        .. include:: ../docstrings/objects.Plot.theme.rst\n\n        \"\"\"\n        new = self._clone()\n\n        rc = mpl.RcParams(config)\n        new._theme.update(rc)\n\n        return new\n\n    def save(self, loc, **kwargs) -> Plot:\n        \"\"\"\n        Compile the plot and write it to a buffer or file on disk.\n\n        Parameters\n        ----------\n        loc : str, path, or buffer\n            Location on disk to save the figure, or a buffer to write into.\n        kwargs\n            Other keyword arguments are passed through to\n            :meth:`matplotlib.figure.Figure.savefig`.\n\n        \"\"\"\n        # TODO expose important keyword arguments in our signature?\n        with theme_context(self._theme_with_defaults()):\n            self._plot().save(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Compile the plot and display it by hooking into pyplot.\n\n        Calling this method is not necessary to render a plot in notebook context,\n        but it may be in other environments (e.g., in a terminal). After compiling the\n        plot, it calls :func:`matplotlib.pyplot.show` (passing any keyword parameters).\n\n        Unlike other :class:`Plot` methods, there is no return value. This should be\n        the last method you call when specifying a plot.\n\n        \"\"\"\n        # TODO make pyplot configurable at the class level, and when not using,\n        # import IPython.display and call on self to populate cell output?\n\n        # Keep an eye on whether matplotlib implements \"attaching\" an existing\n        # figure to pyplot: https://github.com/matplotlib/matplotlib/pull/14024\n\n        self.plot(pyplot=True).show(**kwargs)\n\n    def plot(self, pyplot: bool = False) -> Plotter:\n        \"\"\"\n        Compile the plot spec and return the Plotter object.\n        \"\"\"\n        with theme_context(self._theme_with_defaults()):\n            return self._plot(pyplot)\n\n    def _plot(self, pyplot: bool = False) -> Plotter:\n\n        # TODO if we have _target object, pyplot should be determined by whether it\n        # is hooked into the pyplot state machine (how do we check?)\n\n        plotter = Plotter(pyplot=pyplot, theme=self._theme_with_defaults())\n\n        # Process the variable assignments and initialize the figure\n        common, layers = plotter._extract_data(self)\n        plotter._setup_figure(self, common, layers)\n\n        # Process the scale spec for coordinate variables and transform their data\n        coord_vars = [v for v in self._variables if re.match(r\"^x|y\", v)]\n        plotter._setup_scales(self, common, layers, coord_vars)\n\n        # Apply statistical transform(s)\n        plotter._compute_stats(self, layers)\n\n        # Process scale spec for semantic variables and coordinates computed by stat\n        plotter._setup_scales(self, common, layers)\n\n        # TODO Remove these after updating other methods\n        # ---- Maybe have debug= param that attaches these when True?\n        plotter._data = common\n        plotter._layers = layers\n\n        # Process the data for each layer and add matplotlib artists\n        for layer in layers:\n            plotter._plot_layer(self, layer)\n\n        # Add various figure decorations\n        plotter._make_legend(self)\n        plotter._finalize_figure(self)\n\n        return plotter\n\n\n# ---- The plot compilation engine ---------------------------------------------- #\n\n\nclass Plotter:\n    \"\"\"\n    Engine for compiling a :class:`Plot` spec into a Matplotlib figure.\n\n    This class is not intended to be instantiated directly by users.\n\n    \"\"\"\n    # TODO decide if we ever want these (Plot.plot(debug=True))?\n    _data: PlotData\n    _layers: list[Layer]\n    _figure: Figure\n\n    def __init__(self, pyplot: bool, theme: dict[str, Any]):\n\n        self._pyplot = pyplot\n        self._theme = theme\n        self._legend_contents: list[tuple[\n            tuple[str, str | int], list[Artist], list[str],\n        ]] = []\n        self._scales: dict[str, Scale] = {}\n\n    def save(self, loc, **kwargs) -> Plotter:  # TODO type args\n        kwargs.setdefault(\"dpi\", 96)\n        try:\n            loc = os.path.expanduser(loc)\n        except TypeError:\n            # loc may be a buffer in which case that would not work\n            pass\n        self._figure.savefig(loc, **kwargs)\n        return self\n\n    def show(self, **kwargs) -> None:\n        \"\"\"\n        Display the plot by hooking into pyplot.\n\n        This method calls :func:`matplotlib.pyplot.show` with any keyword parameters.\n\n        \"\"\"\n        # TODO if we did not create the Plotter with pyplot, is it possible to do this?\n        # If not we should clearly raise.\n        import matplotlib.pyplot as plt\n        with theme_context(self._theme):\n            plt.show(**kwargs)\n\n    # TODO API for accessing the underlying matplotlib objects\n    # TODO what else is useful in the public API for this class?\n\n    def _repr_png_(self) -> tuple[bytes, dict[str, float]] | None:\n\n        # TODO use matplotlib backend directly instead of going through savefig?\n\n        # TODO perhaps have self.show() flip a switch to disable this, so that\n        # user does not end up with two versions of the figure in the output\n\n        # TODO use bbox_inches=\"tight\" like the inline backend?\n        # pro: better results,  con: (sometimes) confusing results\n        # Better solution would be to default (with option to change)\n        # to using constrained/tight layout.\n\n        if Plot.config.display[\"format\"] != \"png\":\n            return None\n\n        buffer = io.BytesIO()\n\n        factor = 2 if Plot.config.display[\"hidpi\"] else 1\n        scaling = Plot.config.display[\"scaling\"] / factor\n        dpi = 96 * factor  # TODO put dpi in Plot.config?\n\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, dpi=dpi, format=\"png\", bbox_inches=\"tight\")\n        data = buffer.getvalue()\n\n        w, h = Image.open(buffer).size\n        metadata = {\"width\": w * scaling, \"height\": h * scaling}\n        return data, metadata\n\n    def _repr_svg_(self) -> str | None:\n\n        if Plot.config.display[\"format\"] != \"svg\":\n            return None\n\n        # TODO DPI for rasterized artists?\n\n        scaling = Plot.config.display[\"scaling\"]\n\n        buffer = io.StringIO()\n        with theme_context(self._theme):  # TODO _theme_with_defaults?\n            self._figure.savefig(buffer, format=\"svg\", bbox_inches=\"tight\")\n\n        root = ElementTree.fromstring(buffer.getvalue())\n        w = scaling * float(root.attrib[\"width\"][:-2])\n        h = scaling * float(root.attrib[\"height\"][:-2])\n        root.attrib.update(width=f\"{w}pt\", height=f\"{h}pt\", viewbox=f\"0 0 {w} {h}\")\n        ElementTree.ElementTree(root).write(out := io.BytesIO())\n\n        return out.getvalue().decode()\n\n    def _extract_data(self, p: Plot) -> tuple[PlotData, list[Layer]]:\n\n        common_data = (\n            p._data\n            .join(None, p._facet_spec.get(\"variables\"))\n            .join(None, p._pair_spec.get(\"variables\"))\n        )\n\n        layers: list[Layer] = []\n        for layer in p._layers:\n            spec = layer.copy()\n            spec[\"data\"] = common_data.join(layer.get(\"source\"), layer.get(\"vars\"))\n            layers.append(spec)\n\n        return common_data, layers\n\n    def _resolve_label(self, p: Plot, var: str, auto_label: str | None) -> str:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._labels else var[0]\n        else:\n            key = var\n\n        label: str\n        if key in p._labels:\n            manual_label = p._labels[key]\n            if callable(manual_label) and auto_label is not None:\n                label = manual_label(auto_label)\n            else:\n                label = cast(str, manual_label)\n        elif auto_label is None:\n            label = \"\"\n        else:\n            label = auto_label\n        return label\n\n    def _setup_figure(self, p: Plot, common: PlotData, layers: list[Layer]) -> None:\n\n        # --- Parsing the faceting/pairing parameterization to specify figure grid\n\n        subplot_spec = p._subplot_spec.copy()\n        facet_spec = p._facet_spec.copy()\n        pair_spec = p._pair_spec.copy()\n\n        for axis in \"xy\":\n            if axis in p._shares:\n                subplot_spec[f\"share{axis}\"] = p._shares[axis]\n\n        for dim in [\"col\", \"row\"]:\n            if dim in common.frame and dim not in facet_spec[\"structure\"]:\n                order = categorical_order(common.frame[dim])\n                facet_spec[\"structure\"][dim] = order\n\n        self._subplots = subplots = Subplots(subplot_spec, facet_spec, pair_spec)\n\n        # --- Figure initialization\n        self._figure = subplots.init_figure(\n            pair_spec, self._pyplot, p._figure_spec, p._target,\n        )\n\n        # --- Figure annotation\n        for sub in subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n\n                # ~~ Axis labels\n\n                # TODO Should we make it possible to use only one x/y label for\n                # all rows/columns in a faceted plot? Maybe using sub{axis}label,\n                # although the alignments of the labels from that method leaves\n                # something to be desired (in terms of how it defines 'centered').\n                names = [\n                    common.names.get(axis_key),\n                    *(layer[\"data\"].names.get(axis_key) for layer in layers)\n                ]\n                auto_label = next((name for name in names if name is not None), None)\n                label = self._resolve_label(p, axis_key, auto_label)\n                ax.set(**{f\"{axis}label\": label})\n\n                # ~~ Decoration visibility\n\n                # TODO there should be some override (in Plot.layout?) so that\n                # axis / tick labels can be shown on interior shared axes if desired\n\n                axis_obj = getattr(ax, f\"{axis}axis\")\n                visible_side = {\"x\": \"bottom\", \"y\": \"left\"}.get(axis)\n                show_axis_label = (\n                    sub[visible_side]\n                    or not p._pair_spec.get(\"cross\", True)\n                    or (\n                        axis in p._pair_spec.get(\"structure\", {})\n                        and bool(p._pair_spec.get(\"wrap\"))\n                    )\n                )\n                axis_obj.get_label().set_visible(show_axis_label)\n\n                show_tick_labels = (\n                    show_axis_label\n                    or subplot_spec.get(f\"share{axis}\") not in (\n                        True, \"all\", {\"x\": \"col\", \"y\": \"row\"}[axis]\n                    )\n                )\n                for group in (\"major\", \"minor\"):\n                    side = {\"x\": \"bottom\", \"y\": \"left\"}[axis]\n                    axis_obj.set_tick_params(**{f\"label{side}\": show_tick_labels})\n                    for t in getattr(axis_obj, f\"get_{group}ticklabels\")():\n                        t.set_visible(show_tick_labels)\n\n            # TODO we want right-side titles for row facets in most cases?\n            # Let's have what we currently call \"margin titles\" but properly using the\n            # ax.set_title interface (see my gist)\n            title_parts = []\n            for dim in [\"col\", \"row\"]:\n                if sub[dim] is not None:\n                    val = self._resolve_label(p, \"title\", f\"{sub[dim]}\")\n                    if dim in p._labels:\n                        key = self._resolve_label(p, dim, common.names.get(dim))\n                        val = f\"{key} {val}\"\n                    title_parts.append(val)\n\n            has_col = sub[\"col\"] is not None\n            has_row = sub[\"row\"] is not None\n            show_title = (\n                has_col and has_row\n                or (has_col or has_row) and p._facet_spec.get(\"wrap\")\n                or (has_col and sub[\"top\"])\n                # TODO or has_row and sub[\"right\"] and <right titles>\n                or has_row  # TODO and not <right titles>\n            )\n            if title_parts:\n                title = \" | \".join(title_parts)\n                title_text = ax.set_title(title)\n                title_text.set_visible(show_title)\n            elif not (has_col or has_row):\n                title = self._resolve_label(p, \"title\", None)\n                title_text = ax.set_title(title)\n\n    def _compute_stats(self, spec: Plot, layers: list[Layer]) -> None:\n\n        grouping_vars = [v for v in PROPERTIES if v not in \"xy\"]\n        grouping_vars += [\"col\", \"row\", \"group\"]\n\n        pair_vars = spec._pair_spec.get(\"structure\", {})\n\n        for layer in layers:\n\n            data = layer[\"data\"]\n            mark = layer[\"mark\"]\n            stat = layer[\"stat\"]\n\n            if stat is None:\n                continue\n\n            iter_axes = itertools.product(*[\n                pair_vars.get(axis, [axis]) for axis in \"xy\"\n            ])\n\n            old = data.frame\n\n            if pair_vars:\n                data.frames = {}\n                data.frame = data.frame.iloc[:0]  # TODO to simplify typing\n\n            for coord_vars in iter_axes:\n\n                pairings = \"xy\", coord_vars\n\n                df = old.copy()\n                scales = self._scales.copy()\n\n                for axis, var in zip(*pairings):\n                    if axis != var:\n                        df = df.rename(columns={var: axis})\n                        drop_cols = [x for x in df if re.match(rf\"{axis}\\d+\", str(x))]\n                        df = df.drop(drop_cols, axis=1)\n                        scales[axis] = scales[var]\n\n                orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n                if stat.group_by_orient:\n                    grouper = [orient, *grouping_vars]\n                else:\n                    grouper = grouping_vars\n                groupby = GroupBy(grouper)\n                res = stat(df, groupby, orient, scales)\n\n                if pair_vars:\n                    data.frames[coord_vars] = res\n                else:\n                    data.frame = res\n\n    def _get_scale(\n        self, p: Plot, var: str, prop: Property, values: Series\n    ) -> Scale:\n\n        if re.match(r\"[xy]\\d+\", var):\n            key = var if var in p._scales else var[0]\n        else:\n            key = var\n\n        if key in p._scales:\n            arg = p._scales[key]\n            if arg is None or isinstance(arg, Scale):\n                scale = arg\n            else:\n                scale = prop.infer_scale(arg, values)\n        else:\n            scale = prop.default_scale(values)\n\n        return scale\n\n    def _get_subplot_data(self, df, var, view, share_state):\n\n        if share_state in [True, \"all\"]:\n            # The all-shared case is easiest, every subplot sees all the data\n            seed_values = df[var]\n        else:\n            # Otherwise, we need to setup separate scales for different subplots\n            if share_state in [False, \"none\"]:\n                # Fully independent axes are also easy: use each subplot's data\n                idx = self._get_subplot_index(df, view)\n            elif share_state in df:\n                # Sharing within row/col is more complicated\n                use_rows = df[share_state] == view[share_state]\n                idx = df.index[use_rows]\n            else:\n                # This configuration doesn't make much sense, but it's fine\n                idx = df.index\n\n            seed_values = df.loc[idx, var]\n\n        return seed_values\n\n    def _setup_scales(\n        self,\n        p: Plot,\n        common: PlotData,\n        layers: list[Layer],\n        variables: list[str] | None = None,\n    ) -> None:\n\n        if variables is None:\n            # Add variables that have data but not a scale, which happens\n            # because this method can be called multiple time, to handle\n            # variables added during the Stat transform.\n            variables = []\n            for layer in layers:\n                variables.extend(layer[\"data\"].frame.columns)\n                for df in layer[\"data\"].frames.values():\n                    variables.extend(str(v) for v in df if v not in variables)\n            variables = [v for v in variables if v not in self._scales]\n\n        for var in variables:\n\n            # Determine whether this is a coordinate variable\n            # (i.e., x/y, paired x/y, or derivative such as xmax)\n            m = re.match(r\"^(?P<coord>(?P<axis>x|y)\\d*).*\", var)\n            if m is None:\n                coord = axis = None\n            else:\n                coord = m[\"coord\"]\n                axis = m[\"axis\"]\n\n            # Get keys that handle things like x0, xmax, properly where relevant\n            prop_key = var if axis is None else axis\n            scale_key = var if coord is None else coord\n\n            if prop_key not in PROPERTIES:\n                continue\n\n            # Concatenate layers, using only the relevant coordinate and faceting vars,\n            # This is unnecessarily wasteful, as layer data will often be redundant.\n            # But figuring out the minimal amount we need is more complicated.\n            cols = [var, \"col\", \"row\"]\n            parts = [common.frame.filter(cols)]\n            for layer in layers:\n                parts.append(layer[\"data\"].frame.filter(cols))\n                for df in layer[\"data\"].frames.values():\n                    parts.append(df.filter(cols))\n            var_df = pd.concat(parts, ignore_index=True)\n\n            prop = PROPERTIES[prop_key]\n            scale = self._get_scale(p, scale_key, prop, var_df[var])\n\n            if scale_key not in p._variables:\n                # TODO this implies that the variable was added by the stat\n                # It allows downstream orientation inference to work properly.\n                # But it feels rather hacky, so ideally revisit.\n                scale._priority = 0  # type: ignore\n\n            if axis is None:\n                # We could think about having a broader concept of (un)shared properties\n                # In general, not something you want to do (different scales in facets)\n                # But could make sense e.g. with paired plots. Build later.\n                share_state = None\n                subplots = []\n            else:\n                share_state = self._subplots.subplot_spec[f\"share{axis}\"]\n                subplots = [view for view in self._subplots if view[axis] == coord]\n\n            if scale is None:\n                self._scales[var] = Scale._identity()\n            else:\n                try:\n                    self._scales[var] = scale._setup(var_df[var], prop)\n                except Exception as err:\n                    raise PlotSpecError._during(\"Scale setup\", var) from err\n\n            if axis is None or (var != coord and coord in p._variables):\n                # Everything below here applies only to coordinate variables\n                continue\n\n            # Set up an empty series to receive the transformed values.\n            # We need this to handle piecemeal transforms of categories -> floats.\n            transformed_data = []\n            for layer in layers:\n                index = layer[\"data\"].frame.index\n                empty_series = pd.Series(dtype=float, index=index, name=var)\n                transformed_data.append(empty_series)\n\n            for view in subplots:\n\n                axis_obj = getattr(view[\"ax\"], f\"{axis}axis\")\n                seed_values = self._get_subplot_data(var_df, var, view, share_state)\n                view_scale = scale._setup(seed_values, prop, axis=axis_obj)\n                view[\"ax\"].set(**{f\"{axis}scale\": view_scale._matplotlib_scale})\n\n                for layer, new_series in zip(layers, transformed_data):\n                    layer_df = layer[\"data\"].frame\n                    if var not in layer_df:\n                        continue\n\n                    idx = self._get_subplot_index(layer_df, view)\n                    try:\n                        new_series.loc[idx] = view_scale(layer_df.loc[idx, var])\n                    except Exception as err:\n                        spec_error = PlotSpecError._during(\"Scaling operation\", var)\n                        raise spec_error from err\n\n            # Now the transformed data series are complete, update the layer data\n            for layer, new_series in zip(layers, transformed_data):\n                layer_df = layer[\"data\"].frame\n                if var in layer_df:\n                    layer_df[var] = pd.to_numeric(new_series)\n\n    def _plot_layer(self, p: Plot, layer: Layer) -> None:\n\n        data = layer[\"data\"]\n        mark = layer[\"mark\"]\n        move = layer[\"move\"]\n\n        default_grouping_vars = [\"col\", \"row\", \"group\"]  # TODO where best to define?\n        grouping_properties = [v for v in PROPERTIES if v[0] not in \"xy\"]\n\n        pair_variables = p._pair_spec.get(\"structure\", {})\n\n        for subplots, df, scales in self._generate_pairings(data, pair_variables):\n\n            orient = layer[\"orient\"] or mark._infer_orient(scales)\n\n            def get_order(var):\n                # Ignore order for x/y: they have been scaled to numeric indices,\n                # so any original order is no longer valid. Default ordering rules\n                # sorted unique numbers will correctly reconstruct intended order\n                # TODO This is tricky, make sure we add some tests for this\n                if var not in \"xy\" and var in scales:\n                    return getattr(scales[var], \"order\", None)\n\n            if orient in df:\n                width = pd.Series(index=df.index, dtype=float)\n                for view in subplots:\n                    view_idx = self._get_subplot_data(\n                        df, orient, view, p._shares.get(orient)\n                    ).index\n                    view_df = df.loc[view_idx]\n                    if \"width\" in mark._mappable_props:\n                        view_width = mark._resolve(view_df, \"width\", None)\n                    elif \"width\" in df:\n                        view_width = view_df[\"width\"]\n                    else:\n                        view_width = 0.8  # TODO what default?\n                    spacing = scales[orient]._spacing(view_df.loc[view_idx, orient])\n                    width.loc[view_idx] = view_width * spacing\n                df[\"width\"] = width\n\n            if \"baseline\" in mark._mappable_props:\n                # TODO what marks should have this?\n                # If we can set baseline with, e.g., Bar(), then the\n                # \"other\" (e.g. y for x oriented bars) parameterization\n                # is somewhat ambiguous.\n                baseline = mark._resolve(df, \"baseline\", None)\n            else:\n                # TODO unlike width, we might not want to add baseline to data\n                # if the mark doesn't use it. Practically, there is a concern about\n                # Mark abstraction like Area / Ribbon\n                baseline = 0 if \"baseline\" not in df else df[\"baseline\"]\n            df[\"baseline\"] = baseline\n\n            if move is not None:\n                moves = move if isinstance(move, list) else [move]\n                for move_step in moves:\n                    move_by = getattr(move_step, \"by\", None)\n                    if move_by is None:\n                        move_by = grouping_properties\n                    move_groupers = [*move_by, *default_grouping_vars]\n                    if move_step.group_by_orient:\n                        move_groupers.insert(0, orient)\n                    order = {var: get_order(var) for var in move_groupers}\n                    groupby = GroupBy(order)\n                    df = move_step(df, groupby, orient, scales)\n\n            df = self._unscale_coords(subplots, df, orient)\n\n            grouping_vars = mark._grouping_props + default_grouping_vars\n            split_generator = self._setup_split_generator(grouping_vars, df, subplots)\n\n            mark._plot(split_generator, scales, orient)\n\n        # TODO is this the right place for this?\n        for view in self._subplots:\n            view[\"ax\"].autoscale_view()\n\n        if layer[\"legend\"]:\n            self._update_legend_contents(p, mark, data, scales, layer[\"label\"])\n\n    def _unscale_coords(\n        self, subplots: list[dict], df: DataFrame, orient: str,\n    ) -> DataFrame:\n        # TODO do we still have numbers in the variable name at this point?\n        coord_cols = [c for c in df if re.match(r\"^[xy]\\D*$\", str(c))]\n        out_df = (\n            df\n            .drop(coord_cols, axis=1)\n            .reindex(df.columns, axis=1)  # So unscaled columns retain their place\n            .copy(deep=False)\n        )\n\n        for view in subplots:\n            view_df = self._filter_subplot_data(df, view)\n            axes_df = view_df[coord_cols]\n            for var, values in axes_df.items():\n\n                axis = getattr(view[\"ax\"], f\"{str(var)[0]}axis\")\n                # TODO see https://github.com/matplotlib/matplotlib/issues/22713\n                transform = axis.get_transform().inverted().transform\n                inverted = transform(values)\n                out_df.loc[values.index, str(var)] = inverted\n\n        return out_df\n\n    def _generate_pairings(\n        self, data: PlotData, pair_variables: dict,\n    ) -> Generator[\n        tuple[list[dict], DataFrame, dict[str, Scale]], None, None\n    ]:\n        # TODO retype return with subplot_spec or similar\n\n        iter_axes = itertools.product(*[\n            pair_variables.get(axis, [axis]) for axis in \"xy\"\n        ])\n\n        for x, y in iter_axes:\n\n            subplots = []\n            for view in self._subplots:\n                if (view[\"x\"] == x) and (view[\"y\"] == y):\n                    subplots.append(view)\n\n            if data.frame.empty and data.frames:\n                out_df = data.frames[(x, y)].copy()\n            elif not pair_variables:\n                out_df = data.frame.copy()\n            else:\n                if data.frame.empty and data.frames:\n                    out_df = data.frames[(x, y)].copy()\n                else:\n                    out_df = data.frame.copy()\n\n            scales = self._scales.copy()\n            if x in out_df:\n                scales[\"x\"] = self._scales[x]\n            if y in out_df:\n                scales[\"y\"] = self._scales[y]\n\n            for axis, var in zip(\"xy\", (x, y)):\n                if axis != var:\n                    out_df = out_df.rename(columns={var: axis})\n                    cols = [col for col in out_df if re.match(rf\"{axis}\\d+\", str(col))]\n                    out_df = out_df.drop(cols, axis=1)\n\n            yield subplots, out_df, scales\n\n    def _get_subplot_index(self, df: DataFrame, subplot: dict) -> Index:\n\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df.index\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df.index[keep_rows]\n\n    def _filter_subplot_data(self, df: DataFrame, subplot: dict) -> DataFrame:\n        # TODO note redundancies with preceding function ... needs refactoring\n        dims = df.columns.intersection([\"col\", \"row\"])\n        if dims.empty:\n            return df\n\n        keep_rows = pd.Series(True, df.index, dtype=bool)\n        for dim in dims:\n            keep_rows &= df[dim] == subplot[dim]\n        return df[keep_rows]\n\n    def _setup_split_generator(\n        self, grouping_vars: list[str], df: DataFrame, subplots: list[dict[str, Any]],\n    ) -> Callable[[], Generator]:\n\n        grouping_keys = []\n        grouping_vars = [\n            v for v in grouping_vars if v in df and v not in [\"col\", \"row\"]\n        ]\n        for var in grouping_vars:\n            order = getattr(self._scales[var], \"order\", None)\n            if order is None:\n                order = categorical_order(df[var])\n            grouping_keys.append(order)\n\n        def split_generator(keep_na=False) -> Generator:\n\n            for view in subplots:\n\n                axes_df = self._filter_subplot_data(df, view)\n\n                axes_df_inf_as_nan = axes_df.copy()\n                axes_df_inf_as_nan = axes_df_inf_as_nan.mask(\n                    axes_df_inf_as_nan.isin([np.inf, -np.inf]), np.nan\n                )\n                if keep_na:\n                    # The simpler thing to do would be x.dropna().reindex(x.index).\n                    # But that doesn't work with the way that the subset iteration\n                    # is written below, which assumes data for grouping vars.\n                    # Matplotlib (usually?) masks nan data, so this should \"work\".\n                    # Downstream code can also drop these rows, at some speed cost.\n                    present = axes_df_inf_as_nan.notna().all(axis=1)\n                    nulled = {}\n                    for axis in \"xy\":\n                        if axis in axes_df:\n                            nulled[axis] = axes_df[axis].where(present)\n                    axes_df = axes_df_inf_as_nan.assign(**nulled)\n                else:\n                    axes_df = axes_df_inf_as_nan.dropna()\n\n                subplot_keys = {}\n                for dim in [\"col\", \"row\"]:\n                    if view[dim] is not None:\n                        subplot_keys[dim] = view[dim]\n\n                if not grouping_vars or not any(grouping_keys):\n                    if not axes_df.empty:\n                        yield subplot_keys, axes_df.copy(), view[\"ax\"]\n                    continue\n\n                grouped_df = axes_df.groupby(\n                    grouping_vars, sort=False, as_index=False, observed=False,\n                )\n\n                for key in itertools.product(*grouping_keys):\n\n                    pd_key = (\n                        key[0] if len(key) == 1 and _version_predates(pd, \"2.2.0\")\n                        else key\n                    )\n                    try:\n                        df_subset = grouped_df.get_group(pd_key)\n                    except KeyError:\n                        # TODO (from initial work on categorical plots refactor)\n                        # We are adding this to allow backwards compatability\n                        # with the empty artists that old categorical plots would\n                        # add (before 0.12), which we may decide to break, in which\n                        # case this option could be removed\n                        df_subset = axes_df.loc[[]]\n\n                    if df_subset.empty:\n                        continue\n\n                    sub_vars = dict(zip(grouping_vars, key))\n                    sub_vars.update(subplot_keys)\n\n                    # TODO need copy(deep=...) policy (here, above, anywhere else?)\n                    yield sub_vars, df_subset.copy(), view[\"ax\"]\n\n        return split_generator\n\n    def _update_legend_contents(\n        self,\n        p: Plot,\n        mark: Mark,\n        data: PlotData,\n        scales: dict[str, Scale],\n        layer_label: str | None,\n    ) -> None:\n        \"\"\"Add legend artists / labels for one layer in the plot.\"\"\"\n        if data.frame.empty and data.frames:\n            legend_vars: list[str] = []\n            for frame in data.frames.values():\n                frame_vars = frame.columns.intersection(list(scales))\n                legend_vars.extend(v for v in frame_vars if v not in legend_vars)\n        else:\n            legend_vars = list(data.frame.columns.intersection(list(scales)))\n\n        # First handle layer legends, which occupy a single entry in legend_contents.\n        if layer_label is not None:\n            legend_title = str(p._labels.get(\"legend\", \"\"))\n            layer_key = (legend_title, -1)\n            artist = mark._legend_artist([], None, {})\n            if artist is not None:\n                for content in self._legend_contents:\n                    if content[0] == layer_key:\n                        content[1].append(artist)\n                        content[2].append(layer_label)\n                        break\n                else:\n                    self._legend_contents.append((layer_key, [artist], [layer_label]))\n\n        # Then handle the scale legends\n        # First pass: Identify the values that will be shown for each variable\n        schema: list[tuple[\n            tuple[str, str | int], list[str], tuple[list[Any], list[str]]\n        ]] = []\n        schema = []\n        for var in legend_vars:\n            var_legend = scales[var]._legend\n            if var_legend is not None:\n                values, labels = var_legend\n                for (_, part_id), part_vars, _ in schema:\n                    if data.ids[var] == part_id:\n                        # Allow multiple plot semantics to represent same data variable\n                        part_vars.append(var)\n                        break\n                else:\n                    title = self._resolve_label(p, var, data.names[var])\n                    entry = (title, data.ids[var]), [var], (values, labels)\n                    schema.append(entry)\n\n        # Second pass, generate an artist corresponding to each value\n        contents: list[tuple[tuple[str, str | int], Any, list[str]]] = []\n        for key, variables, (values, labels) in schema:\n            artists = []\n            for val in values:\n                artist = mark._legend_artist(variables, val, scales)\n                if artist is not None:\n                    artists.append(artist)\n            if artists:\n                contents.append((key, artists, labels))\n\n        self._legend_contents.extend(contents)\n\n    def _make_legend(self, p: Plot) -> None:\n        \"\"\"Create the legend artist(s) and add onto the figure.\"\"\"\n        # Combine artists representing same information across layers\n        # Input list has an entry for each distinct variable in each layer\n        # Output dict has an entry for each distinct variable\n        merged_contents: dict[\n            tuple[str, str | int], tuple[list[tuple[Artist, ...]], list[str]],\n        ] = {}\n        for key, new_artists, labels in self._legend_contents:\n            # Key is (name, id); we need the id to resolve variable uniqueness,\n            # but will need the name in the next step to title the legend\n            if key not in merged_contents:\n                # Matplotlib accepts a tuple of artists and will overlay them\n                new_artist_tuples = [tuple([a]) for a in new_artists]\n                merged_contents[key] = new_artist_tuples, labels\n            else:\n                existing_artists = merged_contents[key][0]\n                for i, new_artist in enumerate(new_artists):\n                    existing_artists[i] += tuple([new_artist])\n\n        # When using pyplot, an \"external\" legend won't be shown, so this\n        # keeps it inside the axes (though still attached to the figure)\n        # This is necessary because matplotlib layout engines currently don't\n        # support figure legends \u2014 ideally this will change.\n        loc = \"center right\" if self._pyplot else \"center left\"\n\n        base_legend = None\n        for (name, _), (handles, labels) in merged_contents.items():\n\n            legend = mpl.legend.Legend(\n                self._figure,\n                handles,  # type: ignore  # matplotlib/issues/26639\n                labels,\n                title=name,\n                loc=loc,\n                bbox_to_anchor=(.98, .55),\n            )\n\n            if base_legend:\n                # Matplotlib has no public API for this so it is a bit of a hack.\n                # Ideally we'd define our own legend class with more flexibility,\n                # but that is a lot of work!\n                base_legend_box = base_legend.get_children()[0]\n                this_legend_box = legend.get_children()[0]\n                base_legend_box.get_children().extend(this_legend_box.get_children())\n            else:\n                base_legend = legend\n                self._figure.legends.append(legend)\n\n    def _finalize_figure(self, p: Plot) -> None:\n\n        for sub in self._subplots:\n            ax = sub[\"ax\"]\n            for axis in \"xy\":\n                axis_key = sub[axis]\n                axis_obj = getattr(ax, f\"{axis}axis\")\n\n                # Axis limits\n                if axis_key in p._limits or axis in p._limits:\n                    convert_units = getattr(ax, f\"{axis}axis\").convert_units\n                    a, b = p._limits.get(axis_key) or p._limits[axis]\n                    lo = a if a is None else convert_units(a)\n                    hi = b if b is None else convert_units(b)\n                    if isinstance(a, str):\n                        lo = cast(float, lo) - 0.5\n                    if isinstance(b, str):\n                        hi = cast(float, hi) + 0.5\n                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n\n                if axis_key in self._scales:  # TODO when would it not be?\n                    self._scales[axis_key]._finalize(p, axis_obj)\n\n        if (engine_name := p._layout_spec.get(\"engine\", default)) is not default:\n            # None is a valid arg for Figure.set_layout_engine, hence `default`\n            set_layout_engine(self._figure, engine_name)\n        elif p._target is None:\n            # Don't modify the layout engine if the user supplied their own\n            # matplotlib figure and didn't specify an engine through Plot\n            # TODO switch default to \"constrained\"?\n            # TODO either way, make configurable\n            set_layout_engine(self._figure, \"tight\")\n\n        if (extent := p._layout_spec.get(\"extent\")) is not None:\n            engine = get_layout_engine(self._figure)\n            if engine is None:\n                self._figure.subplots_adjust(*extent)\n            else:\n                # Note the different parameterization for the layout engine rect...\n                left, bottom, right, top = extent\n                width, height = right - left, top - bottom\n                try:\n                    # The base LayoutEngine.set method doesn't have rect= so we need\n                    # to avoid typechecking this statement. We also catch a TypeError\n                    # as a plugin LayoutEngine may not support it either.\n                    # Alternatively we could guard this with a check on the engine type,\n                    # but that would make later-developed engines would un-useable.\n                    engine.set(rect=[left, bottom, width, height])  # type: ignore\n                except TypeError:\n                    # Should we warn / raise? Note that we don't expect to get here\n                    # under any normal circumstances.\n                    pass\n"
        ],
        "model_stats": {
            "input_tokens": 17693,
            "output_tokens": 1200,
            "cost": 0.0562325
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Integrate a new color scale type called 'Gradient' into the Seaborn library that can be mapped and tested similarly to existing color scales like 'Nominal' and 'Continuous'. This involves defining the `Gradient` class within the `scales.py` module and its corresponding test cases in both `test_scales.py` and `test_properties.py`. Ensure that the new scale can handle a linear gradient between two colors and can be utilized within existing Seaborn plotting routines.",
        "dynamic_checklist": [
            "Define the `Gradient` scale class and its properties.",
            "Implement a method to calculate color values for a gradient transition between two colors.",
            "Incorporate `Gradient` scale integration in `Color().get_mapping()` function.",
            "Include default, inference, and mapping tests for `Gradient` in `test_properties.py`.",
            "Verify if the gradient color mapping works correctly with `cat_vector`, `num_vector`, and `bool_vector`."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1313,
            "cost": 0.0444725
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Add the capability to handle multiple normalization methods, specifically 'z-score' and 'min-max', to the `Continuous` scale class used in test cases. This requires modifying the `Continuous` class to accept a normalization parameter and adjusting tests in `test_scales.py` and `test_properties.py` to validate the correctness of these normalization methods.",
        "dynamic_checklist": [
            "Modify the `Continuous` scale class to accept normalization parameters.",
            "Implement 'z-score' and 'min-max' normalization methods within the class.",
            "Update existing tests to include cases that verify each normalization method.",
            "Ensure all transformation-related assertions adapt to the new normalization handling.",
            "Document the changes and new parameters within both module and test docstrings."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1313,
            "cost": 0.0444725
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Implement additional tick customization options such as 'dash style' in the `Continuous` scale's tick setting functions and test these options in the `test_scales.py`. This feature should allow users to specify different dash patterns for axis ticks when using Seaborn plots.",
        "dynamic_checklist": [
            "Extend `setup_ticks` method to accept dash style options.",
            "Ensure `PseudoAxis` handles dash customization properly.",
            "Add tests for various dash styles in tick setup for `Continuous` scale.",
            "Validate that dash styles are visually impacting tick appearances within plots.",
            "Review and update any related documentation for tick customization functionalities."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1313,
            "cost": 0.0444725
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Develop an advanced categorical data visualization property that displays both numeric and categorical data hues, such as aggregating numeric data into bins that are mapped to color gradients in the `Nominal` scale. Test the behavior and appearance of this mapping in the `test_properties.py`.",
        "dynamic_checklist": [
            "Create a function to convert numeric data into categorical bins.",
            "Map color gradients to different bins in the `Nominal` scale.",
            "Include new tests in `TestNominal` to validate binning and hue mapping.",
            "Ensure compatibility of hue mapping with existing categorical plotting functions.",
            "Revise documentation to explain the new numeric-categorical hue property."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1313,
            "cost": 0.0444725
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Integrate support for DateTime axis with additional functionalities like formatting control for different time spans in the `Temporal` scale. Modify the `test_scales.py` to include test cases that cover axis setup with these new DateTime functionalities.",
        "dynamic_checklist": [
            "Enhance `Temporal` class to handle different DateTime formatting.",
            "Implement logic to dynamically select formats based on time spans.",
            "Create tests that assert correct configuration of DateTime axis formats.",
            "Ensure robustness of axis operations over varying DateTime data ranges.",
            "Provide comprehensive documentation updates and examples for DateTime usage."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1313,
            "cost": 0.0444725
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Introduce the ability to accept data in a nested list format to the `Nominal` scale when organizing coordinate properties, and write test cases in `test_properties.py` that ensure the nesting is managed appropriately and consistently in Seaborn plots.",
        "dynamic_checklist": [
            "Refactor `Nominal` to process nested list inputs for coordinate setup.",
            "Implement functions to flatten and interpret nested lists accurately.",
            "Write new tests in `test_properties.py` to verify nested list handling.",
            "Ensure `PseudoAxis` and formatter correctly align with the nested data.",
            "Update technical documentation detailing support for nested list structures."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1313,
            "cost": 0.0444725
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Enhance the `Boolean` scale to support additional truthy/falsey value types beyond native Boolean values and strings, updating relevant tests in `test_scales.py` to ensure the processing of different data types is accurate and maintains integrity.",
        "dynamic_checklist": [
            "Expand `Boolean` scale to recognize custom truthy/falsey values.",
            "Ensure flexible conversion of various data types to Boolean logic.",
            "Add diverse data type cases to `TestBoolean` to check flexibility of scale.",
            "Confirm that all boolean evaluations retain accuracy in Seaborn functionalities.",
            "Update documentation to reflect new capabilities in handling Boolean logic."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1313,
            "cost": 0.0444725
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Create a feature inside the `test_properties.py` to allow dynamic theme setting for test cases, whereby test functions can specify or toggle between 'dark', 'light', and 'custom', and corresponding colors or styles for plotting attributes should adjust automatically. Test whether different themes affect visual output as expected.",
        "dynamic_checklist": [
            "Develop a theme selection mechanism within test context setup.",
            "Implement logic in properties that adapts styling based on theme choice.",
            "Ensure each test case can specify or toggle themes easily and effectively.",
            "Include assertions to verify that theme changes reflect in visual output.",
            "Expand documentation to cover the theme setup and any associated benefits."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1313,
            "cost": 0.0444725
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Introduce advanced error handling for invalid data types provided to coordinate properties in both continuous and nominal scales, ensuring tests in `test_properties.py` and `test_scales.py` correctly evaluate new error messages and handling scenarios.",
        "dynamic_checklist": [
            "Implement error checking for unsupported data types in `Coordinate`.",
            "Update `Nominal` and `Continuous` scale classes for improved error logic.",
            "Create tests that attempt to use invalid data types with newly defined scales.",
            "Verify error messages and exceptions are clear and accurate in test validations.",
            "Enhance documentation to include explanations of typical coordinate failures."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1313,
            "cost": 0.0444725
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_scales.py\n```python3\nimport re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_core/test_properties.py\n```python3\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Develop new scaling options for the `PointSize` property that allows for stepped intervals rather than linear, thereby increasing granularity in plot visualizations. Test its impact in the `test_properties.py` using synthetic datasets that demonstrate the stepped scaling visually and numerically.",
        "dynamic_checklist": [
            "Integrate stepped interval logic into `PointSize` scaling function.",
            "Modify scaling calculations to accommodate distinct step variations.",
            "Create diversified test scenarios to highlight stepped interval usefulness.",
            "Ensure mapping correctness via visual inspections of generated plots.",
            "Update all relevant documentation to detail new optional scaling features."
        ],
        "context_files": [
            "import re\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\nfrom pandas.testing import assert_series_equal\n\nfrom seaborn._core.plot import Plot\nfrom seaborn._core.scales import (\n    Nominal,\n    Continuous,\n    Boolean,\n    Temporal,\n    PseudoAxis,\n)\nfrom seaborn._core.properties import (\n    IntervalProperty,\n    ObjectProperty,\n    Coordinate,\n    Alpha,\n    Color,\n    Fill,\n)\nfrom seaborn.palettes import color_palette\nfrom seaborn.utils import _version_predates\n\n\nclass TestContinuous:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([1, 3, 9], name=\"x\", dtype=float)\n\n    def setup_ticks(self, x, *args, **kwargs):\n\n        s = Continuous().tick(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        return a\n\n    def setup_labels(self, x, *args, **kwargs):\n\n        s = Continuous().label(*args, **kwargs)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(0, 1)\n        locs = a.major.locator()\n        return a, locs\n\n    def test_coordinate_defaults(self, x):\n\n        s = Continuous()._setup(x, Coordinate())\n        assert_series_equal(s(x), x)\n\n    def test_coordinate_transform(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.log10(x))\n\n    def test_coordinate_transform_with_parameter(self, x):\n\n        s = Continuous(trans=\"pow3\")._setup(x, Coordinate())\n        assert_series_equal(s(x), np.power(x, 3))\n\n    def test_coordinate_transform_error(self, x):\n\n        s = Continuous(trans=\"bad\")\n        with pytest.raises(ValueError, match=\"Unknown value provided\"):\n            s._setup(x, Coordinate())\n\n    def test_interval_defaults(self, x):\n\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [0, .25, 1])\n\n    def test_interval_with_range(self, x):\n\n        s = Continuous((1, 3))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 1.5, 3])\n\n    def test_interval_with_norm(self, x):\n\n        s = Continuous(norm=(3, 7))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [-.5, 0, 1.5])\n\n    def test_interval_with_range_norm_and_transform(self, x):\n\n        x = pd.Series([1, 10, 100])\n        # TODO param order?\n        s = Continuous((2, 3), (10, 100), \"log\")._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 2, 3])\n\n    def test_interval_with_bools(self):\n\n        x = pd.Series([True, False, False])\n        s = Continuous()._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [1, 0, 0])\n\n    def test_color_defaults(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous()._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, x):\n\n        cmap = color_palette(\"viridis\", as_cmap=True)\n        s = Continuous(\"viridis\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_tuple_values(self, x):\n\n        cmap = color_palette(\"blend:b,g\", as_cmap=True)\n        s = Continuous((\"b\", \"g\"))._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_callable_values(self, x):\n\n        cmap = color_palette(\"light:r\", as_cmap=True)\n        s = Continuous(cmap)._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .25, 1])[:, :3])  # FIXME RGBA\n\n    def test_color_with_norm(self, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(norm=(3, 7))._setup(x, Color())\n        assert_array_equal(s(x), cmap([-.5, 0, 1.5])[:, :3])  # FIXME RGBA\n\n    def test_color_with_transform(self, x):\n\n        x = pd.Series([1, 10, 100], name=\"x\", dtype=float)\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Continuous(trans=\"log\")._setup(x, Color())\n        assert_array_equal(s(x), cmap([0, .5, 1])[:, :3])  # FIXME RGBA\n\n    def test_tick_locator(self, x):\n\n        locs = [.2, .5, .8]\n        locator = mpl.ticker.FixedLocator(locs)\n        a = self.setup_ticks(x, locator)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_locator_input_check(self, x):\n\n        err = \"Tick locator must be an instance of .*?, not <class 'tuple'>.\"\n        with pytest.raises(TypeError, match=err):\n            Continuous().tick((1, 2))\n\n    def test_tick_upto(self, x):\n\n        for n in [2, 5, 10]:\n            a = self.setup_ticks(x, upto=n)\n            assert len(a.major.locator()) <= (n + 1)\n\n    def test_tick_every(self, x):\n\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d)\n            assert np.allclose(np.diff(a.major.locator()), d)\n\n    def test_tick_every_between(self, x):\n\n        lo, hi = .2, .8\n        for d in [.05, .2, .5]:\n            a = self.setup_ticks(x, every=d, between=(lo, hi))\n            expected = np.arange(lo, hi + d, d)\n            assert_array_equal(a.major.locator(), expected)\n\n    def test_tick_at(self, x):\n\n        locs = [.2, .5, .9]\n        a = self.setup_ticks(x, at=locs)\n        assert_array_equal(a.major.locator(), locs)\n\n    def test_tick_count(self, x):\n\n        n = 8\n        a = self.setup_ticks(x, count=n)\n        assert_array_equal(a.major.locator(), np.linspace(0, 1, n))\n\n    def test_tick_count_between(self, x):\n\n        n = 5\n        lo, hi = .2, .7\n        a = self.setup_ticks(x, count=n, between=(lo, hi))\n        assert_array_equal(a.major.locator(), np.linspace(lo, hi, n))\n\n    def test_tick_minor(self, x):\n\n        n = 3\n        a = self.setup_ticks(x, count=2, minor=n)\n        expected = np.linspace(0, 1, n + 2)\n        if _version_predates(mpl, \"3.8.0rc1\"):\n            # I am not sure why matplotlib <3.8  minor ticks include the\n            # largest major location but exclude the smalllest one ...\n            expected = expected[1:]\n        assert_array_equal(a.minor.locator(), expected)\n\n    def test_log_tick_default(self, x):\n\n        s = Continuous(trans=\"log\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        ticks = a.major.locator()\n        assert np.allclose(np.diff(np.log10(ticks)), 1)\n\n    def test_log_tick_upto(self, x):\n\n        n = 3\n        s = Continuous(trans=\"log\").tick(upto=n)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        assert a.major.locator.numticks == n\n\n    def test_log_tick_count(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`count` requires\"):\n            Continuous(trans=\"log\").tick(count=4)\n\n        s = Continuous(trans=\"log\").tick(count=4, between=(1, 1000))\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(.5, 1050)\n        assert_array_equal(a.major.locator(), [1, 10, 100, 1000])\n\n    def test_log_tick_format_disabled(self, x):\n\n        s = Continuous(trans=\"log\").label(base=None)._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(20, 20000)\n        labels = a.major.formatter.format_ticks(a.major.locator())\n        for text in labels:\n            assert re.match(r\"^\\d+$\", text)\n\n    def test_log_tick_every(self, x):\n\n        with pytest.raises(RuntimeError, match=\"`every` not supported\"):\n            Continuous(trans=\"log\").tick(every=2)\n\n    def test_symlog_tick_default(self, x):\n\n        s = Continuous(trans=\"symlog\")._setup(x, Coordinate())\n        a = PseudoAxis(s._matplotlib_scale)\n        a.set_view_interval(-1050, 1050)\n        ticks = a.major.locator()\n        assert ticks[0] == -ticks[-1]\n        pos_ticks = np.sort(np.unique(np.abs(ticks)))\n        assert np.allclose(np.diff(np.log10(pos_ticks[1:])), 1)\n        assert pos_ticks[0] == 0\n\n    def test_label_formatter(self, x):\n\n        fmt = mpl.ticker.FormatStrFormatter(\"%.3f\")\n        a, locs = self.setup_labels(x, fmt)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{3}$\", text)\n\n    def test_label_like_pattern(self, x):\n\n        a, locs = self.setup_labels(x, like=\".4f\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^\\d\\.\\d{4}$\", text)\n\n    def test_label_like_string(self, x):\n\n        a, locs = self.setup_labels(x, like=\"x = {x:.1f}\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^x = \\d\\.\\d$\", text)\n\n    def test_label_like_function(self, x):\n\n        a, locs = self.setup_labels(x, like=\"{:^5.1f}\".format)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels:\n            assert re.match(r\"^ \\d\\.\\d $\", text)\n\n    def test_label_base(self, x):\n\n        a, locs = self.setup_labels(100 * x, base=2)\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:]:\n            assert not text or \"2^\" in text\n\n    def test_label_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"g\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+ mg$\", text)\n\n    def test_label_unit_with_sep(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=(\"\", \"g\"))\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+mg$\", text)\n\n    def test_label_empty_unit(self, x):\n\n        a, locs = self.setup_labels(1000 * x, unit=\"\")\n        labels = a.major.formatter.format_ticks(locs)\n        for text in labels[1:-1]:\n            assert re.match(r\"^\\d+m$\", text)\n\n    def test_label_base_from_transform(self, x):\n\n        s = Continuous(trans=\"log\")\n        a = PseudoAxis(s._setup(x, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert r\"10^{2}\" in label\n\n    def test_label_type_checks(self):\n\n        s = Continuous()\n        with pytest.raises(TypeError, match=\"Label formatter must be\"):\n            s.label(\"{x}\")\n\n        with pytest.raises(TypeError, match=\"`like` must be\"):\n            s.label(like=2)\n\n\nclass TestNominal:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([\"a\", \"c\", \"b\", \"c\"], name=\"x\")\n\n    @pytest.fixture\n    def y(self):\n        return pd.Series([1, -1.5, 3, -1.5], name=\"y\")\n\n    def test_coordinate_defaults(self, x):\n\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n\n    def test_coordinate_with_order(self, x):\n\n        s = Nominal(order=[\"a\", \"b\", \"c\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n\n    def test_coordinate_with_subset_order(self, x):\n\n        s = Nominal(order=[\"c\", \"a\"])._setup(x, Coordinate())\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 1, 2, 1], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"a\", \"c\", \"b\"]\n\n    def test_coordinate_axis_with_order(self, x):\n\n        order = [\"a\", \"b\", \"c\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([0, 2, 1, 2], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == order\n\n    def test_coordinate_axis_with_subset_order(self, x):\n\n        order = [\"c\", \"a\"]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 0, np.nan, 0], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [*order, \"\"]\n\n    def test_coordinate_axis_with_category_dtype(self, x):\n\n        order = [\"b\", \"a\", \"d\", \"c\"]\n        x = x.astype(pd.CategoricalDtype(order))\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), np.array([1, 3, 0, 3], float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2, 3]) == order\n\n    def test_coordinate_numeric_data(self, y):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([1, 0, 2, 0], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"-1.5\", \"1.0\", \"3.0\"]\n\n    def test_coordinate_numeric_data_with_order(self, y):\n\n        order = [1, 4, -1.5]\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal(order=order)._setup(y, Coordinate(), ax.yaxis)\n        assert_array_equal(s(y), np.array([0, 2, np.nan, 2], float))\n        f = ax.yaxis.get_major_formatter()\n        assert f.format_ticks([0, 1, 2]) == [\"1.0\", \"4.0\", \"-1.5\"]\n\n    def test_color_defaults(self, x):\n\n        s = Nominal()._setup(x, Color())\n        cs = color_palette()\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_named_palette(self, x):\n\n        pal = \"flare\"\n        s = Nominal(pal)._setup(x, Color())\n        cs = color_palette(pal, 3)\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 3)\n        pal = dict(zip(\"bac\", cs))\n        s = Nominal(pal)._setup(x, Color())\n        assert_array_equal(s(x), [cs[1], cs[2], cs[0], cs[2]])\n\n    def test_color_numeric_data(self, y):\n\n        s = Nominal()._setup(y, Color())\n        cs = color_palette()\n        assert_array_equal(s(y), [cs[1], cs[0], cs[2], cs[0]])\n\n    def test_color_numeric_with_order_subset(self, y):\n\n        s = Nominal(order=[-1.5, 1])._setup(y, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(y), [c2, c1, null, c1])\n\n    @pytest.mark.xfail(reason=\"Need to sort out float/int order\")\n    def test_color_numeric_int_float_mix(self):\n\n        z = pd.Series([1, 2], name=\"z\")\n        s = Nominal(order=[1.0, 2])._setup(z, Color())\n        c1, c2 = color_palette(n_colors=2)\n        null = (np.nan, np.nan, np.nan)\n        assert_array_equal(s(z), [c1, null, c2])\n\n    def test_color_alpha_in_palette(self, x):\n\n        cs = [(.2, .2, .3, .5), (.1, .2, .3, 1), (.5, .6, .2, 0)]\n        s = Nominal(cs)._setup(x, Color())\n        assert_array_equal(s(x), [cs[0], cs[1], cs[2], cs[1]])\n\n    def test_color_unknown_palette(self, x):\n\n        pal = \"not_a_palette\"\n        err = f\"'{pal}' is not a valid palette name\"\n        with pytest.raises(ValueError, match=err):\n            Nominal(pal)._setup(x, Color())\n\n    def test_object_defaults(self, x):\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return list(\"xyz\"[:n])\n\n        s = Nominal()._setup(x, MockProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", \"z\", \"y\"]\n\n    def test_object_dict(self, x):\n\n        vs = {\"a\": \"x\", \"b\": \"y\", \"c\": \"z\"}\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"z\", \"y\", \"z\"]\n\n    def test_object_order(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n        s = Nominal(vs, order=[\"c\", \"a\", \"b\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"y\", \"x\", \"z\", \"x\"]\n\n    def test_object_order_subset(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Nominal(vs, order=[\"a\", \"c\"])._setup(x, ObjectProperty())\n        assert s(x) == [\"x\", \"y\", None, \"y\"]\n\n    def test_objects_that_are_weird(self, x):\n\n        vs = [(\"x\", 1), (None, None, 0), {}]\n        s = Nominal(vs)._setup(x, ObjectProperty())\n        assert s(x) == [vs[0], vs[1], vs[2], vs[1]]\n\n    def test_alpha_default(self, x):\n\n        s = Nominal()._setup(x, Alpha())\n        assert_array_equal(s(x), [.95, .625, .3, .625])\n\n    def test_fill(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, True, False, True])\n\n    def test_fill_dict(self):\n\n        x = pd.Series([\"a\", \"a\", \"b\", \"a\"], name=\"x\")\n        vs = {\"a\": False, \"b\": True}\n        s = Nominal(vs)._setup(x, Fill())\n        assert_array_equal(s(x), [False, False, True, False])\n\n    def test_fill_nunique_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\", \"a\", \"b\"], name=\"x\")\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            s = Nominal()._setup(x, Fill())\n        assert_array_equal(s(x), [True, False, True, True, False])\n\n    def test_interval_defaults(self, x):\n\n        class MockProperty(IntervalProperty):\n            _default_range = (1, 2)\n\n        s = Nominal()._setup(x, MockProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple(self, x):\n\n        s = Nominal((1, 2))._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 1.5, 1, 1.5])\n\n    def test_interval_tuple_numeric(self, y):\n\n        s = Nominal((1, 2))._setup(y, IntervalProperty())\n        assert_array_equal(s(y), [1.5, 2, 1, 2])\n\n    def test_interval_list(self, x):\n\n        vs = [2, 5, 4]\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [2, 5, 4, 5])\n\n    def test_interval_dict(self, x):\n\n        vs = {\"a\": 3, \"b\": 4, \"c\": 6}\n        s = Nominal(vs)._setup(x, IntervalProperty())\n        assert_array_equal(s(x), [3, 6, 4, 6])\n\n    def test_interval_with_transform(self, x):\n\n        class MockProperty(IntervalProperty):\n            _forward = np.square\n            _inverse = np.sqrt\n\n        s = Nominal((2, 4))._setup(x, MockProperty())\n        assert_array_equal(s(x), [4, np.sqrt(10), 2, np.sqrt(10)])\n\n    def test_empty_data(self):\n\n        x = pd.Series([], dtype=object, name=\"x\")\n        s = Nominal()._setup(x, Coordinate())\n        assert_array_equal(s(x), [])\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Nominal()._setup(x, Coordinate(), ax.yaxis)\n        s._finalize(Plot(), ax.yaxis)\n\n        levels = x.unique()\n        assert ax.get_ylim() == (len(levels) - .5, -.5)\n        assert_array_equal(ax.get_yticks(), list(range(len(levels))))\n        for i, expected in enumerate(levels):\n            assert ax.yaxis.major.formatter(i) == expected\n\n\nclass TestTemporal:\n\n    @pytest.fixture\n    def t(self):\n        dates = pd.to_datetime([\"1972-09-27\", \"1975-06-24\", \"1980-12-14\"])\n        return pd.Series(dates, name=\"x\")\n\n    @pytest.fixture\n    def x(self, t):\n        return pd.Series(mpl.dates.date2num(t), name=t.name)\n\n    def test_coordinate_defaults(self, t, x):\n\n        s = Temporal()._setup(t, Coordinate())\n        assert_array_equal(s(t), x)\n\n    def test_interval_defaults(self, t, x):\n\n        s = Temporal()._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), normed)\n\n    def test_interval_with_range(self, t, x):\n\n        values = (1, 3)\n        s = Temporal((1, 3))._setup(t, IntervalProperty())\n        normed = (x - x.min()) / (x.max() - x.min())\n        expected = normed * (values[1] - values[0]) + values[0]\n        assert_array_equal(s(t), expected)\n\n    def test_interval_with_norm(self, t, x):\n\n        norm = t[1], t[2]\n        s = Temporal(norm=norm)._setup(t, IntervalProperty())\n        n = mpl.dates.date2num(norm)\n        normed = (x - n[0]) / (n[1] - n[0])\n        assert_array_equal(s(t), normed)\n\n    def test_color_defaults(self, t, x):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        s = Temporal()._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_color_named_values(self, t, x):\n\n        name = \"viridis\"\n        cmap = color_palette(name, as_cmap=True)\n        s = Temporal(name)._setup(t, Color())\n        normed = (x - x.min()) / (x.max() - x.min())\n        assert_array_equal(s(t), cmap(normed)[:, :3])  # FIXME RGBA\n\n    def test_coordinate_axis(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Temporal()._setup(t, Coordinate(), ax.xaxis)\n        assert_array_equal(s(t), x)\n        locator = ax.xaxis.get_major_locator()\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(locator, mpl.dates.AutoDateLocator)\n        assert isinstance(formatter, mpl.dates.AutoDateFormatter)\n\n    def test_tick_locator(self, t):\n\n        locator = mpl.dates.YearLocator(month=3, day=15)\n        s = Temporal().tick(locator)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(0, 365)\n        assert 73 in a.major.locator()\n\n    def test_tick_upto(self, t, x):\n\n        n = 8\n        ax = mpl.figure.Figure().subplots()\n        Temporal().tick(upto=n)._setup(t, Coordinate(), ax.xaxis)\n        locator = ax.xaxis.get_major_locator()\n        assert set(locator.maxticks.values()) == {n}\n\n    def test_label_formatter(self, t):\n\n        formatter = mpl.dates.DateFormatter(\"%Y\")\n        s = Temporal().label(formatter)\n        a = PseudoAxis(s._setup(t, Coordinate())._matplotlib_scale)\n        a.set_view_interval(10, 1000)\n        label, = a.major.formatter.format_ticks([100])\n        assert label == \"1970\"\n\n    def test_label_concise(self, t, x):\n\n        ax = mpl.figure.Figure().subplots()\n        Temporal().label(concise=True)._setup(t, Coordinate(), ax.xaxis)\n        formatter = ax.xaxis.get_major_formatter()\n        assert isinstance(formatter, mpl.dates.ConciseDateFormatter)\n\n\nclass TestBoolean:\n\n    @pytest.fixture\n    def x(self):\n        return pd.Series([True, False, False, True], name=\"x\", dtype=bool)\n\n    def test_coordinate(self, x):\n\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_coordinate_axis(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        assert_array_equal(s(x), x.astype(float))\n        f = ax.xaxis.get_major_formatter()\n        assert f.format_ticks([0, 1]) == [\"False\", \"True\"]\n\n    @pytest.mark.parametrize(\n        \"dtype,value\",\n        [\n            (object, np.nan),\n            (object, None),\n            (\"boolean\", pd.NA),\n        ]\n    )\n    def test_coordinate_missing(self, x, dtype, value):\n\n        x = x.astype(dtype)\n        x[2] = value\n        s = Boolean()._setup(x, Coordinate())\n        assert_array_equal(s(x), x.astype(float))\n\n    def test_color_defaults(self, x):\n\n        s = Boolean()._setup(x, Color())\n        cs = color_palette()\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_list_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_tuple_palette(self, x):\n\n        cs = tuple(color_palette(\"crest\", 2))\n        s = Boolean(cs)._setup(x, Color())\n        expected = [cs[int(x_i)] for x_i in ~x]\n        assert_array_equal(s(x), expected)\n\n    def test_color_dict_palette(self, x):\n\n        cs = color_palette(\"crest\", 2)\n        pal = {True: cs[0], False: cs[1]}\n        s = Boolean(pal)._setup(x, Color())\n        expected = [pal[x_i] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_object_defaults(self, x):\n\n        vs = [\"x\", \"y\", \"z\"]\n\n        class MockProperty(ObjectProperty):\n            def _default_values(self, n):\n                return vs[:n]\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_list(self, x):\n\n        vs = [\"x\", \"y\"]\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[int(x_i)] for x_i in ~x]\n        assert s(x) == expected\n\n    def test_object_dict(self, x):\n\n        vs = {True: \"x\", False: \"y\"}\n        s = Boolean(vs)._setup(x, ObjectProperty())\n        expected = [vs[x_i] for x_i in x]\n        assert s(x) == expected\n\n    def test_fill(self, x):\n\n        s = Boolean()._setup(x, Fill())\n        assert_array_equal(s(x), x)\n\n    def test_interval_defaults(self, x):\n\n        vs = (1, 2)\n\n        class MockProperty(IntervalProperty):\n            _default_range = vs\n\n        s = Boolean()._setup(x, MockProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_interval_tuple(self, x):\n\n        vs = (3, 5)\n        s = Boolean(vs)._setup(x, IntervalProperty())\n        expected = [vs[int(x_i)] for x_i in x]\n        assert_array_equal(s(x), expected)\n\n    def test_finalize(self, x):\n\n        ax = mpl.figure.Figure().subplots()\n        s = Boolean()._setup(x, Coordinate(), ax.xaxis)\n        s._finalize(Plot(), ax.xaxis)\n        assert ax.get_xlim() == (1.5, -.5)\n        assert_array_equal(ax.get_xticks(), [0, 1])\n        assert ax.xaxis.major.formatter(0) == \"False\"\n        assert ax.xaxis.major.formatter(1) == \"True\"\n",
            "\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nfrom matplotlib.colors import same_color, to_rgb, to_rgba\nfrom matplotlib.markers import MarkerStyle\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.rules import categorical_order\nfrom seaborn._core.scales import Nominal, Continuous, Boolean\nfrom seaborn._core.properties import (\n    Alpha,\n    Color,\n    Coordinate,\n    EdgeWidth,\n    Fill,\n    LineStyle,\n    LineWidth,\n    Marker,\n    PointSize,\n)\nfrom seaborn._compat import get_colormap\nfrom seaborn.palettes import color_palette\n\n\nclass DataFixtures:\n\n    @pytest.fixture\n    def num_vector(self, long_df):\n        return long_df[\"s\"]\n\n    @pytest.fixture\n    def num_order(self, num_vector):\n        return categorical_order(num_vector)\n\n    @pytest.fixture\n    def cat_vector(self, long_df):\n        return long_df[\"a\"]\n\n    @pytest.fixture\n    def cat_order(self, cat_vector):\n        return categorical_order(cat_vector)\n\n    @pytest.fixture\n    def dt_num_vector(self, long_df):\n        return long_df[\"t\"]\n\n    @pytest.fixture\n    def dt_cat_vector(self, long_df):\n        return long_df[\"d\"]\n\n    @pytest.fixture\n    def bool_vector(self, long_df):\n        return long_df[\"x\"] > 10\n\n    @pytest.fixture\n    def vectors(self, num_vector, cat_vector, bool_vector):\n        return {\"num\": num_vector, \"cat\": cat_vector, \"bool\": bool_vector}\n\n\nclass TestCoordinate(DataFixtures):\n\n    def test_bad_scale_arg_str(self, num_vector):\n\n        err = \"Unknown magic arg for x scale: 'xxx'.\"\n        with pytest.raises(ValueError, match=err):\n            Coordinate(\"x\").infer_scale(\"xxx\", num_vector)\n\n    def test_bad_scale_arg_type(self, cat_vector):\n\n        err = \"Magic arg for x scale must be str, not list.\"\n        with pytest.raises(TypeError, match=err):\n            Coordinate(\"x\").infer_scale([1, 2, 3], cat_vector)\n\n\nclass TestColor(DataFixtures):\n\n    def assert_same_rgb(self, a, b):\n        assert_array_equal(a[:, :3], b[:, :3])\n\n    def test_nominal_default_palette(self, cat_vector, cat_order):\n\n        m = Color().get_mapping(Nominal(), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(None, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_default_palette_large(self):\n\n        vector = pd.Series(list(\"abcdefghijklmnopqrstuvwxyz\"))\n        m = Color().get_mapping(Nominal(), vector)\n        actual = m(np.arange(26))\n        expected = color_palette(\"husl\", 26)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_named_palette(self, cat_vector, cat_order):\n\n        palette = \"Blues\"\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = color_palette(palette, n)\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_list_palette(self, cat_vector, cat_order):\n\n        palette = color_palette(\"Reds\", len(cat_order))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        actual = m(np.arange(len(palette)))\n        expected = palette\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_palette(self, cat_vector, cat_order):\n\n        colors = color_palette(\"Greens\")\n        palette = dict(zip(cat_order, colors))\n        m = Color().get_mapping(Nominal(palette), cat_vector)\n        n = len(cat_order)\n        actual = m(np.arange(n))\n        expected = colors\n        for have, want in zip(actual, expected):\n            assert same_color(have, want)\n\n    def test_nominal_dict_with_missing_keys(self, cat_vector, cat_order):\n\n        palette = dict(zip(cat_order[1:], color_palette(\"Purples\")))\n        with pytest.raises(ValueError, match=\"No entry in color dict\"):\n            Color(\"color\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_short(self, cat_vector, cat_order):\n\n        n = len(cat_order) - 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has fewer values \\({n}\\) than needed \\({n + 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_nominal_list_too_long(self, cat_vector, cat_order):\n\n        n = len(cat_order) + 1\n        palette = color_palette(\"Oranges\", n)\n        msg = rf\"The edgecolor list has more values \\({n}\\) than needed \\({n - 1}\\)\"\n        with pytest.warns(UserWarning, match=msg):\n            Color(\"edgecolor\").get_mapping(Nominal(palette), cat_vector)\n\n    def test_continuous_default_palette(self, num_vector):\n\n        cmap = color_palette(\"ch:\", as_cmap=True)\n        m = Color().get_mapping(Continuous(), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_named_palette(self, num_vector):\n\n        pal = \"flare\"\n        cmap = color_palette(pal, as_cmap=True)\n        m = Color().get_mapping(Continuous(pal), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_tuple_palette(self, num_vector):\n\n        vals = (\"blue\", \"red\")\n        cmap = color_palette(\"blend:\" + \",\".join(vals), as_cmap=True)\n        m = Color().get_mapping(Continuous(vals), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_callable_palette(self, num_vector):\n\n        cmap = get_colormap(\"viridis\")\n        m = Color().get_mapping(Continuous(cmap), num_vector)\n        self.assert_same_rgb(m(num_vector), cmap(num_vector))\n\n    def test_continuous_missing(self):\n\n        x = pd.Series([1, 2, np.nan, 4])\n        m = Color().get_mapping(Continuous(), x)\n        assert np.isnan(m(x)[2]).all()\n\n    def test_bad_scale_values_continuous(self, num_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Continuous\"):\n            Color().get_mapping(Continuous([\"r\", \"g\", \"b\"]), num_vector)\n\n    def test_bad_scale_values_nominal(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"Scale values for color with a Nominal\"):\n            Color().get_mapping(Nominal(get_colormap(\"viridis\")), cat_vector)\n\n    def test_bad_inference_arg(self, cat_vector):\n\n        with pytest.raises(TypeError, match=\"A single scale argument for color\"):\n            Color().infer_scale(123, cat_vector)\n\n    @pytest.mark.parametrize(\n        \"data_type,scale_class\",\n        [(\"cat\", Nominal), (\"num\", Continuous), (\"bool\", Boolean)]\n    )\n    def test_default(self, data_type, scale_class, vectors):\n\n        scale = Color().default_scale(vectors[data_type])\n        assert isinstance(scale, scale_class)\n\n    def test_default_numeric_data_category_dtype(self, num_vector):\n\n        scale = Color().default_scale(num_vector.astype(\"category\"))\n        assert isinstance(scale, Nominal)\n\n    def test_default_binary_data(self):\n\n        x = pd.Series([0, 0, 1, 0, 1], dtype=int)\n        scale = Color().default_scale(x)\n        assert isinstance(scale, Continuous)\n\n    @pytest.mark.parametrize(\n        \"values,data_type,scale_class\",\n        [\n            (\"viridis\", \"cat\", Nominal),  # Based on variable type\n            (\"viridis\", \"num\", Continuous),  # Based on variable type\n            (\"viridis\", \"bool\", Boolean),  # Based on variable type\n            (\"muted\", \"num\", Nominal),  # Based on qualitative palette\n            ([\"r\", \"g\", \"b\"], \"num\", Nominal),  # Based on list palette\n            ({2: \"r\", 4: \"g\", 8: \"b\"}, \"num\", Nominal),  # Based on dict palette\n            ((\"r\", \"b\"), \"num\", Continuous),  # Based on tuple / variable type\n            ((\"g\", \"m\"), \"cat\", Nominal),  # Based on tuple / variable type\n            ((\"c\", \"y\"), \"bool\", Boolean),  # Based on tuple / variable type\n            (get_colormap(\"inferno\"), \"num\", Continuous),  # Based on callable\n        ]\n    )\n    def test_inference(self, values, data_type, scale_class, vectors):\n\n        scale = Color().infer_scale(values, vectors[data_type])\n        assert isinstance(scale, scale_class)\n        assert scale.values == values\n\n    def test_standardization(self):\n\n        f = Color().standardize\n        assert f(\"C3\") == to_rgb(\"C3\")\n        assert f(\"dodgerblue\") == to_rgb(\"dodgerblue\")\n\n        assert f((.1, .2, .3)) == (.1, .2, .3)\n        assert f((.1, .2, .3, .4)) == (.1, .2, .3, .4)\n\n        assert f(\"#123456\") == to_rgb(\"#123456\")\n        assert f(\"#12345678\") == to_rgba(\"#12345678\")\n\n        assert f(\"#123\") == to_rgb(\"#123\")\n        assert f(\"#1234\") == to_rgba(\"#1234\")\n\n\nclass ObjectPropertyBase(DataFixtures):\n\n    def assert_equal(self, a, b):\n\n        assert self.unpack(a) == self.unpack(b)\n\n    def unpack(self, x):\n        return x\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        scale = self.prop().default_scale(vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        scale = self.prop().infer_scale(self.values, vectors[data_type])\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == self.values\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(categorical_order(x), self.values))\n        scale = self.prop().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_dict_missing(self, cat_vector):\n\n        levels = categorical_order(cat_vector)\n        values = dict(zip(levels, self.values[:-1]))\n        scale = Nominal(values)\n        name = self.prop.__name__.lower()\n        msg = f\"No entry in {name} dictionary for {repr(levels[-1])}\"\n        with pytest.raises(ValueError, match=msg):\n            self.prop().get_mapping(scale, cat_vector)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        mapping = self.prop().get_mapping(Nominal(), x)\n        n = x.nunique()\n        for i, expected in enumerate(self.prop()._default_values(n)):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Nominal(self.values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, expected in enumerate(self.standardized_values):\n            actual, = mapping([i])\n            self.assert_equal(actual, expected)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\"])\n    def test_mapping_from_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        levels = categorical_order(x)\n        values = dict(zip(levels, self.values[::-1]))\n        standardized_values = dict(zip(levels, self.standardized_values[::-1]))\n\n        scale = Nominal(values)\n        mapping = self.prop().get_mapping(scale, x)\n        for i, level in enumerate(levels):\n            actual, = mapping([i])\n            expected = standardized_values[level]\n            self.assert_equal(actual, expected)\n\n    def test_mapping_with_null_value(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(self.values), cat_vector)\n        actual = mapping(np.array([0, np.nan, 2]))\n        v0, _, v2 = self.standardized_values\n        expected = [v0, self.prop.null_value, v2]\n        for a, b in zip(actual, expected):\n            self.assert_equal(a, b)\n\n    def test_unique_default_large_n(self):\n\n        n = 24\n        x = pd.Series(np.arange(n))\n        mapping = self.prop().get_mapping(Nominal(), x)\n        assert len({self.unpack(x_i) for x_i in mapping(x)}) == n\n\n    def test_bad_scale_values(self, cat_vector):\n\n        var_name = self.prop.__name__.lower()\n        with pytest.raises(TypeError, match=f\"Scale values for a {var_name} variable\"):\n            self.prop().get_mapping(Nominal((\"o\", \"s\")), cat_vector)\n\n\nclass TestMarker(ObjectPropertyBase):\n\n    prop = Marker\n    values = [\"o\", (5, 2, 0), MarkerStyle(\"^\")]\n    standardized_values = [MarkerStyle(x) for x in values]\n\n    def assert_equal(self, a, b):\n        a_path, b_path = a.get_path(), b.get_path()\n        assert_array_equal(a_path.vertices, b_path.vertices)\n        assert_array_equal(a_path.codes, b_path.codes)\n        assert a_path.simplify_threshold == b_path.simplify_threshold\n        assert a_path.should_simplify == b_path.should_simplify\n\n        assert a.get_joinstyle() == b.get_joinstyle()\n        assert a.get_transform().to_values() == b.get_transform().to_values()\n        assert a.get_fillstyle() == b.get_fillstyle()\n\n    def unpack(self, x):\n        return (\n            x.get_path(),\n            x.get_joinstyle(),\n            x.get_transform().to_values(),\n            x.get_fillstyle(),\n        )\n\n\nclass TestLineStyle(ObjectPropertyBase):\n\n    prop = LineStyle\n    values = [\"solid\", \"--\", (1, .5)]\n    standardized_values = [LineStyle._get_dash_pattern(x) for x in values]\n\n    def test_bad_type(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Linestyle must be .+, not list.$\"):\n            p.standardize([1, 2])\n\n    def test_bad_style(self):\n\n        p = LineStyle()\n        with pytest.raises(ValueError, match=\"^Linestyle string must be .+, not 'o'.$\"):\n            p.standardize(\"o\")\n\n    def test_bad_dashes(self):\n\n        p = LineStyle()\n        with pytest.raises(TypeError, match=\"^Invalid dash pattern\"):\n            p.standardize((1, 2, \"x\"))\n\n\nclass TestFill(DataFixtures):\n\n    @pytest.fixture\n    def vectors(self):\n\n        return {\n            \"cat\": pd.Series([\"a\", \"a\", \"b\"]),\n            \"num\": pd.Series([1, 1, 2]),\n            \"bool\": pd.Series([True, True, False])\n        }\n\n    @pytest.fixture\n    def cat_vector(self, vectors):\n        return vectors[\"cat\"]\n\n    @pytest.fixture\n    def num_vector(self, vectors):\n        return vectors[\"num\"]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_default(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().default_scale(x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_list(self, data_type, vectors):\n\n        x = vectors[data_type]\n        scale = Fill().infer_scale([True, False], x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == [True, False]\n\n    @pytest.mark.parametrize(\"data_type\", [\"cat\", \"num\", \"bool\"])\n    def test_inference_dict(self, data_type, vectors):\n\n        x = vectors[data_type]\n        values = dict(zip(x.unique(), [True, False]))\n        scale = Fill().infer_scale(values, x)\n        assert isinstance(scale, Boolean if data_type == \"bool\" else Nominal)\n        assert scale.values == values\n\n    def test_mapping_categorical_data(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal(), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_numeric_data(self, num_vector):\n\n        mapping = Fill().get_mapping(Nominal(), num_vector)\n        assert_array_equal(mapping([0, 1, 0]), [True, False, True])\n\n    def test_mapping_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([False, True]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_truthy_list(self, cat_vector):\n\n        mapping = Fill().get_mapping(Nominal([0, 1]), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_mapping_dict(self, cat_vector):\n\n        values = dict(zip(cat_vector.unique(), [False, True]))\n        mapping = Fill().get_mapping(Nominal(values), cat_vector)\n        assert_array_equal(mapping([0, 1, 0]), [False, True, False])\n\n    def test_cycle_warning(self):\n\n        x = pd.Series([\"a\", \"b\", \"c\"])\n        with pytest.warns(UserWarning, match=\"The variable assigned to fill\"):\n            Fill().get_mapping(Nominal(), x)\n\n    def test_values_error(self):\n\n        x = pd.Series([\"a\", \"b\"])\n        with pytest.raises(TypeError, match=\"Scale values for fill must be\"):\n            Fill().get_mapping(Nominal(\"bad_values\"), x)\n\n\nclass IntervalBase(DataFixtures):\n\n    def norm(self, x):\n        return (x - x.min()) / (x.max() - x.min())\n\n    @pytest.mark.parametrize(\"data_type,scale_class\", [\n        (\"cat\", Nominal),\n        (\"num\", Continuous),\n        (\"bool\", Boolean),\n    ])\n    def test_default(self, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().default_scale(x)\n        assert isinstance(scale, scale_class)\n\n    @pytest.mark.parametrize(\"arg,data_type,scale_class\", [\n        ((1, 3), \"cat\", Nominal),\n        ((1, 3), \"num\", Continuous),\n        ((1, 3), \"bool\", Boolean),\n        ([1, 2, 3], \"cat\", Nominal),\n        ([1, 2, 3], \"num\", Nominal),\n        ([1, 3], \"bool\", Boolean),\n        ({\"a\": 1, \"b\": 3, \"c\": 2}, \"cat\", Nominal),\n        ({2: 1, 4: 3, 8: 2}, \"num\", Nominal),\n        ({True: 4, False: 2}, \"bool\", Boolean),\n    ])\n    def test_inference(self, arg, data_type, scale_class, vectors):\n\n        x = vectors[data_type]\n        scale = self.prop().infer_scale(arg, x)\n        assert isinstance(scale, scale_class)\n        assert scale.values == arg\n\n    def test_mapped_interval_numeric(self, num_vector):\n\n        mapping = self.prop().get_mapping(Continuous(), num_vector)\n        assert_array_equal(mapping([0, 1]), self.prop().default_range)\n\n    def test_mapped_interval_categorical(self, cat_vector):\n\n        mapping = self.prop().get_mapping(Nominal(), cat_vector)\n        n = cat_vector.nunique()\n        assert_array_equal(mapping([n - 1, 0]), self.prop().default_range)\n\n    def test_bad_scale_values_numeric_data(self, num_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_stem = (\n            f\"Values for {prop_name} variables with Continuous scale must be 2-tuple\"\n        )\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not <class 'str'>.\"):\n            self.prop().get_mapping(Continuous(\"abc\"), num_vector)\n\n        with pytest.raises(TypeError, match=f\"{err_stem}; not 3-tuple.\"):\n            self.prop().get_mapping(Continuous((1, 2, 3)), num_vector)\n\n    def test_bad_scale_values_categorical_data(self, cat_vector):\n\n        prop_name = self.prop.__name__.lower()\n        err_text = f\"Values for {prop_name} variables with Nominal scale\"\n        with pytest.raises(TypeError, match=err_text):\n            self.prop().get_mapping(Nominal(\"abc\"), cat_vector)\n\n\nclass TestAlpha(IntervalBase):\n    prop = Alpha\n\n\nclass TestLineWidth(IntervalBase):\n    prop = LineWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"lines.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestEdgeWidth(IntervalBase):\n    prop = EdgeWidth\n\n    def test_rcparam_default(self):\n\n        with mpl.rc_context({\"patch.linewidth\": 2}):\n            assert self.prop().default_range == (1, 4)\n\n\nclass TestPointSize(IntervalBase):\n    prop = PointSize\n\n    def test_areal_scaling_numeric(self, num_vector):\n\n        limits = 5, 10\n        scale = Continuous(limits)\n        mapping = self.prop().get_mapping(scale, num_vector)\n        x = np.linspace(0, 1, 6)\n        expected = np.sqrt(np.linspace(*np.square(limits), num=len(x)))\n        assert_array_equal(mapping(x), expected)\n\n    def test_areal_scaling_categorical(self, cat_vector):\n\n        limits = (2, 4)\n        scale = Nominal(limits)\n        mapping = self.prop().get_mapping(scale, cat_vector)\n        assert_array_equal(mapping(np.arange(3)), [4, np.sqrt(10), 2])\n"
        ],
        "model_stats": {
            "input_tokens": 12537,
            "output_tokens": 1313,
            "cost": 0.0444725
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_dot.py\n```python3\nfrom matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_base.py\n```python3\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Implement a function within the seaborn package that automatically adjusts the marker sizes in plots using the `Dots` and `Dot` classes based on a dataset's statistical properties like standard deviation or variance of the data. This functionality should allow the user to specify a column in the dataset for which the marker sizes will be adjusted proportionally. The new feature should be tested in the existing test files `test_dot.py` and `test_base.py`. You need to account for how these sizes interact with other mappable properties with dependencies within the Mark class.",
        "dynamic_checklist": [
            "Ensure that the new function can accept a dataset and the column to analyze the variance or standard deviation.",
            "Make sure the marker sizes are proportional to the calculated statistical property.",
            "Verify that functions respect all existing Mappable dependencies.",
            "Maintain backward compatibility with existing functionality.",
            "Ensure the feature is reflected in both `Dots` and `Dot`.",
            "Update test cases in `test_dot.py` and `test_base.py`, checking various statistical distributions.",
            "Use assert functions provided in numpy.testing for consistency in test validations.",
            "The changes should not alter the color, shape, or any other unrelated mappable properties of the plot.",
            "Verify that the feature can take into account missing data while calculating variance or standard deviation.",
            "Verify the feature works across different axes instances."
        ],
        "context_files": [
            "from matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n",
            "from dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n"
        ],
        "model_stats": {
            "input_tokens": 3451,
            "output_tokens": 2581,
            "cost": 0.0344375
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_dot.py\n```python3\nfrom matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_base.py\n```python3\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Enhance the visual testing suite in `test_dot.py` to include a utility function that visually compares two seaborn plot outputs by overlaying them with different opacities. This would help visually identify inconsistencies in plot rendering caused by changes in the underlying plot code. This should integrate with the existing `test_base.py` testing strategy, focusing on color resolution and Mappable integration. The implementation should be straightforward to handle missing or occluded data.",
        "dynamic_checklist": [
            "Create a utility function to generate overlay plots with varying opacities.",
            "Ensure clear visual differentiation of both plots when overlayed, manage plot colors and opacities accordingly.",
            "Facilitate automated comparison with some threshold metrics for determining when plots are 'different'.",
            "Integrate with `test_dot.py`, especially for tests like `test_simple` and `test_fill`.",
            "Account for edge cases such as missing data points in the plotted datasets.",
            "Ensure that the overlay function gracefully handles `Mappable` properties from `test_base.py`.",
            "Implement test cases for the new utility function to cover various plotting scenarios.",
            "Validate that plots are created and closed correctly, avoiding resource leaks.",
            "Document this new visual debugging feature to help other developers use it effectively inside the test suite.",
            "Check that the new utility adapts across different Matplotlib backend environments."
        ],
        "context_files": [
            "from matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n",
            "from dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n"
        ],
        "model_stats": {
            "input_tokens": 3451,
            "output_tokens": 2581,
            "cost": 0.0344375
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_dot.py\n```python3\nfrom matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_base.py\n```python3\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Develop an enhancement feature that uses the Mappable class properties in `test_base.py` to automatically suggest color palettes based on the themes being used. Integrating this feature with existing functions in `test_dot.py`, ensure that `Dots` and `Dot` render with aesthetically pleasing and non-clashing color schemes based on a theme that the Plot is using. This feature should also be accessible via the Mark class framework to allow for dynamic behavior as the plot is being drawn.",
        "dynamic_checklist": [
            "Develop logic to retrieve and suggest color palettes based on current theme settings in Matplotlib.",
            "Integrate this color suggestion mechanism with existing Plot configuration such that it automatically updates when a new theme is applied.",
            "Ensure the Mappable class properties can dynamically apply this color palette without altering existing user settings unless specified.",
            "Test the feature thoroughly within `test_dot.py`, especially in relation to the `test_map_color` test case.",
            "Add assertions to confirm that all suggested palettes fit within provided theme constraints without visual clashes.",
            "Ensure backward compatibility within the code, i.e., plots that do not call this feature remain unaffected.",
            "Document how these suggested palettes reflect the Mark class dependencies and influences.",
            "Add test cases to verify that the palette suggestions vary appropriately with different themes.",
            "Investigate edge cases where default palettes might be preferred due to user-defined settings.",
            "Account and log instances where palette suggestion fails or returns a default set due to conflicts."
        ],
        "context_files": [
            "from matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n",
            "from dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n"
        ],
        "model_stats": {
            "input_tokens": 3451,
            "output_tokens": 2581,
            "cost": 0.0344375
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_dot.py\n```python3\nfrom matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_base.py\n```python3\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Incorporate a caching mechanism within the Plots that use `Dots` and `Dot` classes, implemented in `test_dot.py`, to improve rendering efficiency by minimizing data processing for static repetitive datasets. This module should check the dataset consistency across runs and avoid reprocessing unchanged data. The mechanism should seamlessly work with Mappable dependent properties as seen in `test_base.py`.",
        "dynamic_checklist": [
            "Design a caching system to store previously computed dataset renderings, focusing on static dataset states.",
            "Integrate checks for dataset consistency to determine when cached data can be reused.",
            "Ensure that the caching does not conflict with `Mappable` dependencies, using hooks or signals when necessary.",
            "Validate caching performance improvements through new or modified test cases within `test_dot.py`.",
            "Ensure cache invalidation scenarios are well handled and tested, when the dataset or plot parameters change.",
            "Add support for handling large datasets and differentiating which parts of the plot should be dynamic versus static.",
            "Optimize the cache to not significantly increase memory footprint, using efficient data structures or compression.",
            "Leverage existing features in Plot to integrate with themes and scaling attributes without adverse side effects.",
            "Update documentation to detail when and how caching is leveraged, especially for development tuning.",
            "Include performance benchmarks to showcase caching impact on rendering times across typical use cases."
        ],
        "context_files": [
            "from matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n",
            "from dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n"
        ],
        "model_stats": {
            "input_tokens": 3451,
            "output_tokens": 2581,
            "cost": 0.0344375
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_dot.py\n```python3\nfrom matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_base.py\n```python3\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Create a feature to automatically log details about plot creation time and resource usage of plotting operations using the `Dot` and `Dots` markers. This should allow developers to perform diagnostics on plotting performance. Information gathered should include times of various plot stages and memory used during operation. The logging system can leverage existing pytest capabilities that are found in other test cases like those in `test_base.py`.",
        "dynamic_checklist": [
            "Implement a logging system that tracks performance metrics during plot creation and rendering.",
            "Ensure that logs include timestamps for major plotting stages (e.g., setup, rendering, finalization) along with memory usage metrics.",
            "Integrate the logging feature within existing pytest frameworks for easy access and analysis.",
            "Decorate or wrap existing plot operations with timing and resource monitoring functionalities.",
            "Incorporate this feature in both `test_dot.py` and `test_base.py` for various marker tests.",
            "Make sure plots remain visually unchanged by this logging, and that the logging has minimal overhead.",
            "Test logging for correctness and performance under various plotting sizes and complexities.",
            "Enable configuration settings to opt in or out of the logging features depending on the execution environment.",
            "Document the logging system to guide developers in interpreting performance metrics.",
            "Ensure logging can be used across different pytest backends and environments without errors."
        ],
        "context_files": [
            "from matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n",
            "from dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n"
        ],
        "model_stats": {
            "input_tokens": 3451,
            "output_tokens": 2581,
            "cost": 0.0344375
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_dot.py\n```python3\nfrom matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_base.py\n```python3\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Design and implement a utility that serializes the current state and configurations of a plot using `Dot` and `Dots` classes into a JSON object. This utility should include Mappable configurations and be both interpreted and restorable, effectively allowing a plot to be reproduced from a saved state. The implementation should be extendable to account for future changes in plot configurations in both `test_dot.py` and `test_base.py`.",
        "dynamic_checklist": [
            "Ensure the serialization process accurately captures all relevant properties of a plotting instance including Mappable features.",
            "Design a schema within the JSON format which captures plot settings and configurations in an extendable manner.",
            "Implement deserialization that can reinstantiate the plot from the JSON object seamlessly.",
            "Test serialization and deserialization across different test scenarios in `test_dot.py` and `test_base.py`.",
            "Account for potential issues like backward compatibility when future plot features are added.",
            "Ensure the serialized JSON structure is clear, and human-readable where possible, while maintaining necessary details.",
            "Incorporate features to handle missing or optional fields during serialization.",
            "Ensure error handling during the serialization and deserialization process do not halt execution. Instead, line errors should be logged and reported.",
            "Document the usage instructions and JSON schema settings clearly for other developers.",
            "Integrate with existing pytest frameworks to test these operations under various conditions and scenarios."
        ],
        "context_files": [
            "from matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n",
            "from dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n"
        ],
        "model_stats": {
            "input_tokens": 3451,
            "output_tokens": 2581,
            "cost": 0.0344375
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_dot.py\n```python3\nfrom matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_base.py\n```python3\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Introduce a feature that ensures `Dots` and `Dot` plots respect accessibility guidelines such as high contrast colors and sufficient marker size for visual clarity. This should be implemented as an optional toggle. The feature should interact with the existing Mappable configurations from `test_base.py` to adapt color settings appropriately, ensuring the settings do not violate existing themes or user settings.",
        "dynamic_checklist": [
            "Implement a toggleable feature that adjusts plot visibility based on accessibility guidelines.",
            "Ensure color contrasts between markers, backgrounds, and plot themes meet common accessibility standards.",
            "Modify or enhance the current Mappable color configurations to support this feature without breaking existing code.",
            "Add test cases in `test_dot.py` to confirm that turning on accessibility mode results in visible contrast and readability improvements.",
            "Coordinate compatibility with various themes and color palettes, maintaining consistency during toggling operations.",
            "Consult and apply known accessibility standards during feature implementation.",
            "Document how this feature is intended to be used and any limitations or considerations.",
            "Ensure backward compatibility such that existing plots without this feature enabled appear unchanged.",
            "Modify test assertions where necessary, using visibility metrics or color contrast checks.",
            "Handle potential Mappable settings conflicts gracefully, maintaining intended plot appearances."
        ],
        "context_files": [
            "from matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n",
            "from dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n"
        ],
        "model_stats": {
            "input_tokens": 3451,
            "output_tokens": 2581,
            "cost": 0.0344375
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_dot.py\n```python3\nfrom matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_base.py\n```python3\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Enhance the `test_base.py` suite to include tests that validate the robustness and accuracy of default values for all Mappable properties when no user configuration is provided. Integrate these tests with `test_dot.py` to check that Dots and Dot instances fall back to these defaults correctly during plot rendering. Ensure this feature accounts for different rendering backends and theme settings from Plot's configuration.",
        "dynamic_checklist": [
            "Identify all Mappable properties that need default value tests in `test_base.py`.",
            "Develop test cases that manipulate plot creation without custom user configurations, observing resultant defaults.",
            "Ensure all Mappable defaults are correctly applied to both `Dot` and `Dots` markers in `test_dot.py`.",
            "Validate that these defaults function correctly inline with different Plot theme settings and configurations.",
            "Assess that modifications do not impact rendering performance or drastically change default appearances.",
            "Cross-verify defaults with previously documented configurations, ensuring consistency.",
            "Document and log cases where defaults conflict or overlap, especially for resource credentials.",
            "Ensure test coverage spans different Matplotlib backends and theme environments to guarantee reliability.",
            "Automate tests to trigger with default settings identified and updated in pytest exploration.",
            "Monitor the test results to catch unexpected default behaviors, promptly addressing reporting issues."
        ],
        "context_files": [
            "from matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n",
            "from dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n"
        ],
        "model_stats": {
            "input_tokens": 3451,
            "output_tokens": 2581,
            "cost": 0.0344375
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_dot.py\n```python3\nfrom matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_base.py\n```python3\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Implement a feature within `Dots` and `Dot` markers that exports a CSV of data points rendered on a plot for quick analysis and reporting. It should be possible to toggle this feature on during plot generation. The exported data should include all axis values, scales applied, and any mappable properties resolved through `test_base.py` configurations.",
        "dynamic_checklist": [
            "Develop CSV export functionality that captures data points being plotted including axis values and calculated scales.",
            "Ensure integration with both `Dot` and `Dots` classes for complete feature coverage in `test_dot.py`.",
            "Verify that the exported data correctly reflects the resolved Mappable properties including color and size.",
            "Add configuration settings or flags that integrate effortlessly with plot generation to toggle CSV export.",
            "Account for performance impacts of this feature during large data operations, ensuring it remains efficient.",
            "Include detailed logging for export activities, capturing potential edge cases especially with missing data.",
            "Develop user documentation highlighted practical uses of this generated data for analysis and visualization.",
            "Include test cases that verify CSV output consistency, ensuring it reflects rendered plot details accurately.",
            "Test various scenarios within different theme and scaling configurations ensuring data integrity.",
            "Ensure file handling does not disrupt plot rendering and complies with operating system restrictions."
        ],
        "context_files": [
            "from matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n",
            "from dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n"
        ],
        "model_stats": {
            "input_tokens": 3451,
            "output_tokens": 2581,
            "cost": 0.0344375
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_dot.py\n```python3\nfrom matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_marks/test_base.py\n```python3\nfrom dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Build an interaction logger within the `Dots` and `Dot` classes that tracks which elements get rendered, clicked, or hovered over when displayed through Matplotlib. Utilize the data from this logging to understand user interactions post-render and potentially influence statistical tracking or optimizations. Integrate features leveraging pytest in `test_base.py` to simulate interaction scenarios to test functionality and performance.",
        "dynamic_checklist": [
            "Design and implement a logging system to capture render, click, and hover actions on plot elements.",
            "Ensure logs are informative and capture context such as plotted data point details and involved settings.",
            "Simulate and test user interactions in `test_dot.py`, confirming logs capture interaction data accurately.",
            "Utilize pytest features in `test_base.py` to run automated interaction tests across all supported examples.",
            "Validate the performance impact of interaction tracking during complex plot operations, ensuring minimal overhead.",
            "Add configuration to enable or disable the logger based on operational needs and user preferences.",
            "Secure logs for confidentiality when handling sensitive data and document best practices for log storage and management.",
            "Examine logs for potential performance enhancement opportunities or frequent user paths.",
            "Document logger setup, functionality, and how to interpret results for insight extraction.",
            "Ensure interaction tracking aligns with or can be toggled for various matplotlib backends."
        ],
        "context_files": [
            "from matplotlib.colors import to_rgba, to_rgba_array\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn.palettes import color_palette\nfrom seaborn._core.plot import Plot\nfrom seaborn._marks.dot import Dot, Dots\n\n\n@pytest.fixture(autouse=True)\ndef default_palette():\n    with color_palette(\"deep\"):\n        yield\n\n\nclass DotBase:\n\n    def check_offsets(self, points, x, y):\n\n        offsets = points.get_offsets().T\n        assert_array_equal(offsets[0], x)\n        assert_array_equal(offsets[1], y)\n\n    def check_colors(self, part, points, colors, alpha=None):\n\n        rgba = to_rgba_array(colors, alpha)\n\n        getter = getattr(points, f\"get_{part}colors\")\n        assert_array_equal(getter(), rgba)\n\n\nclass TestDot(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, 1)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dot(edgecolor=\"w\", stroke=2, edgewidth=1)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [\"w\", C0], 1)\n\n        expected = [mark.edgewidth, mark.stroke]\n        assert_array_equal(points.get_linewidths(), expected)\n\n    def test_missing_coordinate_data(self):\n\n        x = [1, float(\"nan\"), 3]\n        y = [5, 3, 4]\n\n        p = Plot(x=x, y=y).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n    @pytest.mark.parametrize(\"prop\", [\"color\", \"fill\", \"marker\", \"pointsize\"])\n    def test_missing_semantic_data(self, prop):\n\n        x = [1, 2, 3]\n        y = [5, 3, 4]\n        z = [\"a\", float(\"nan\"), \"b\"]\n\n        p = Plot(x=x, y=y, **{prop: z}).add(Dot()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, [1, 3], [5, 4])\n\n\nclass TestDots(DotBase):\n\n    def test_simple(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        p = Plot(x=x, y=y).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0] * 3, .2)\n        self.check_colors(\"edge\", points, [C0] * 3, 1)\n\n    def test_set_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        m = Dots(color=\".25\")\n        p = Plot(x=x, y=y).add(m).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [m.color] * 3, .2)\n        self.check_colors(\"edge\", points, [m.color] * 3, 1)\n\n    def test_map_color(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots()).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], .2)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_fill(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        c = [\"a\", \"b\", \"a\"]\n        p = Plot(x=x, y=y, color=c).add(Dots(fill=False)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [C0, C1, C0], 0)\n        self.check_colors(\"edge\", points, [C0, C1, C0], 1)\n\n    def test_pointsize(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(pointsize=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_sizes(), [s ** 2] * 3)\n\n    def test_stroke(self):\n\n        x = [1, 2, 3]\n        y = [4, 5, 2]\n        s = 3\n        p = Plot(x=x, y=y).add(Dots(stroke=s)).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        self.check_offsets(points, x, y)\n        assert_array_equal(points.get_linewidths(), [s] * 3)\n\n    def test_filled_unfilled_mix(self):\n\n        x = [1, 2]\n        y = [4, 5]\n        marker = [\"a\", \"b\"]\n        shapes = [\"o\", \"x\"]\n\n        mark = Dots(stroke=2)\n        p = Plot(x=x, y=y).add(mark, marker=marker).scale(marker=shapes).plot()\n        ax = p._figure.axes[0]\n        points, = ax.collections\n        C0, C1, *_ = p._theme[\"axes.prop_cycle\"].by_key()[\"color\"]\n        self.check_offsets(points, x, y)\n        self.check_colors(\"face\", points, [to_rgba(C0, .2), to_rgba(C0, 0)], None)\n        self.check_colors(\"edge\", points, [C0, C0], 1)\n        assert_array_equal(points.get_linewidths(), [mark.stroke] * 2)\n",
            "from dataclasses import dataclass\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._marks.base import Mark, Mappable, resolve_color\n\n\nclass TestMappable:\n\n    def mark(self, **features):\n\n        @dataclass\n        class MockMark(Mark):\n            linewidth: float = Mappable(rc=\"lines.linewidth\")\n            pointsize: float = Mappable(4)\n            color: str = Mappable(\"C0\")\n            fillcolor: str = Mappable(depend=\"color\")\n            alpha: float = Mappable(1)\n            fillalpha: float = Mappable(depend=\"alpha\")\n\n        m = MockMark(**features)\n        return m\n\n    def test_repr(self):\n\n        assert str(Mappable(.5)) == \"<0.5>\"\n        assert str(Mappable(\"CO\")) == \"<'CO'>\"\n        assert str(Mappable(rc=\"lines.linewidth\")) == \"<rc:lines.linewidth>\"\n        assert str(Mappable(depend=\"color\")) == \"<depend:color>\"\n        assert str(Mappable(auto=True)) == \"<auto>\"\n\n    def test_input_checks(self):\n\n        with pytest.raises(AssertionError):\n            Mappable(rc=\"bogus.parameter\")\n        with pytest.raises(AssertionError):\n            Mappable(depend=\"nonexistent_feature\")\n\n    def test_value(self):\n\n        val = 3\n        m = self.mark(linewidth=val)\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_default(self):\n\n        val = 3\n        m = self.mark(linewidth=Mappable(val))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_rcparam(self):\n\n        param = \"lines.linewidth\"\n        val = mpl.rcParams[param]\n\n        m = self.mark(linewidth=Mappable(rc=param))\n        assert m._resolve({}, \"linewidth\") == val\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n    def test_depends(self):\n\n        val = 2\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n\n        m = self.mark(pointsize=Mappable(val), linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val))\n\n        m = self.mark(pointsize=val * 2, linewidth=Mappable(depend=\"pointsize\"))\n        assert m._resolve({}, \"linewidth\") == val * 2\n        assert_array_equal(m._resolve(df, \"linewidth\"), np.full(len(df), val * 2))\n\n    def test_mapped(self):\n\n        values = {\"a\": 1, \"b\": 2, \"c\": 3}\n\n        def f(x):\n            return np.array([values[x_i] for x_i in x])\n\n        m = self.mark(linewidth=Mappable(2))\n        scales = {\"linewidth\": f}\n\n        assert m._resolve({\"linewidth\": \"c\"}, \"linewidth\", scales) == 3\n\n        df = pd.DataFrame({\"linewidth\": [\"a\", \"b\", \"c\"]})\n        expected = np.array([1, 2, 3], float)\n        assert_array_equal(m._resolve(df, \"linewidth\", scales), expected)\n\n    def test_color(self):\n\n        c, a = \"C1\", .5\n        m = self.mark(color=c, alpha=a)\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n\n    def test_color_mapped_alpha(self):\n\n        c = \"r\"\n        values = {\"a\": .2, \"b\": .5, \"c\": .8}\n\n        m = self.mark(color=c, alpha=Mappable(1))\n        scales = {\"alpha\": lambda s: np.array([values[s_i] for s_i in s])}\n\n        assert resolve_color(m, {\"alpha\": \"b\"}, \"\", scales) == mpl.colors.to_rgba(c, .5)\n\n        df = pd.DataFrame({\"alpha\": list(values.keys())})\n\n        # Do this in two steps for mpl 3.2 compat\n        expected = mpl.colors.to_rgba_array([c] * len(df))\n        expected[:, 3] = list(values.values())\n\n        assert_array_equal(resolve_color(m, df, \"\", scales), expected)\n\n    def test_color_scaled_as_strings(self):\n\n        colors = [\"C1\", \"dodgerblue\", \"#445566\"]\n        m = self.mark()\n        scales = {\"color\": lambda s: colors}\n\n        actual = resolve_color(m, {\"color\": pd.Series([\"a\", \"b\", \"c\"])}, \"\", scales)\n        expected = mpl.colors.to_rgba_array(colors)\n        assert_array_equal(actual, expected)\n\n    def test_fillcolor(self):\n\n        c, a = \"green\", .8\n        fa = .2\n        m = self.mark(\n            color=c, alpha=a,\n            fillcolor=Mappable(depend=\"color\"), fillalpha=Mappable(fa),\n        )\n\n        assert resolve_color(m, {}) == mpl.colors.to_rgba(c, a)\n        assert resolve_color(m, {}, \"fill\") == mpl.colors.to_rgba(c, fa)\n\n        df = pd.DataFrame(index=pd.RangeIndex(10))\n        cs = [c] * len(df)\n        assert_array_equal(resolve_color(m, df), mpl.colors.to_rgba_array(cs, a))\n        assert_array_equal(\n            resolve_color(m, df, \"fill\"), mpl.colors.to_rgba_array(cs, fa)\n        )\n"
        ],
        "model_stats": {
            "input_tokens": 3451,
            "output_tokens": 2581,
            "cost": 0.0344375
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_aggregation.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_order.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Enhance the testing framework to validate the behavior of the `Agg` and `Perc` classes when provided with a DataFrame that contains a `None` or `NaN` value in all columns. Ensure that the appropriate handling of missing data is verified by comparing the output with the expected aggregation and percentile calculations.",
        "dynamic_checklist": [
            "Ensure `Agg` and `Perc` can handle DataFrames with `None` or `NaN` values in all columns.",
            "Verify the output against expectations for aggregation and percentile calculations when missing data is present.",
            "Validate that any changes or additions to the classes do not break existing functionality."
        ],
        "context_files": [
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n",
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n"
        ],
        "model_stats": {
            "input_tokens": 2304,
            "output_tokens": 1061,
            "cost": 0.01637
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_aggregation.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_order.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Implement a parameterized test for both `Agg` and `Perc` classes to verify their output is consistent across different data distributions (such as normal, uniform, and binomial distributions). This will help ensure the classes work correctly for various statistical inputs.",
        "dynamic_checklist": [
            "Create DataFrames with various distributions: normal, uniform, and binomial.",
            "Write parameterized tests for both `Agg` and `Perc` classes.",
            "Verify that outputs match statistical expectations for each distribution.",
            "Ensure no regression issues are introduced in the existing test suite."
        ],
        "context_files": [
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n",
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n"
        ],
        "model_stats": {
            "input_tokens": 2304,
            "output_tokens": 1061,
            "cost": 0.01637
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_aggregation.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_order.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Add functionality to the `get_groupby` method in both test files to handle cases where the DataFrame contains more than two non-unique group identifiers. This will enable the method to cater a wider range of DataFrames with multiple grouping columns.",
        "dynamic_checklist": [
            "Modify `get_groupby` to accept and correctly process multiple grouping identifiers.",
            "Ensure backward compatibility with existing test fixtures.",
            "Verify group-by operations still perform correctly for previous tests after modification."
        ],
        "context_files": [
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n",
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n"
        ],
        "model_stats": {
            "input_tokens": 2304,
            "output_tokens": 1061,
            "cost": 0.01637
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_aggregation.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_order.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Introduce a new test in `test_aggregation.py` to cover scenarios where the aggregation function used in `Agg` is replaced by a user-defined function passed as a lambda. This test will help verify that `Agg` can handle custom aggregation logic effectively.",
        "dynamic_checklist": [
            "Develop a test to apply a custom aggregation function via lambda to `Agg`.",
            "Ensure the result of `Agg` with custom function matches manually computed expectations.",
            "Check for robustness and error handling when applying unknown or improperly designed functions."
        ],
        "context_files": [
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n",
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n"
        ],
        "model_stats": {
            "input_tokens": 2304,
            "output_tokens": 1061,
            "cost": 0.01637
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_aggregation.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_order.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Refactor the testing classes to eliminate redundant code, notably the `get_groupby` method which is identical in both test files. Utilize a common fixture or utility function to streamline the code and enhance maintainability of the test suite.",
        "dynamic_checklist": [
            "Create a utility function for `get_groupby` that can be shared between the test files.",
            "Replace current implementations in both `test_aggregation.py` and `test_order.py` with calls to the utility function.",
            "Ensure all existing tests related to this function still pass after refactor."
        ],
        "context_files": [
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n",
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n"
        ],
        "model_stats": {
            "input_tokens": 2304,
            "output_tokens": 1061,
            "cost": 0.01637
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_aggregation.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_order.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Create comprehensive tests in both `test_aggregation.py` and `test_order.py` to ensure that operations involving the orientation parameter in `GroupBy` execute correctly across all possible values. This ensures thorough validation of orientation-based logic.",
        "dynamic_checklist": [
            "Check operation of `GroupBy` with all valid orientation parameters in both test files.",
            "Ensure orientation logic produces expected data manipulations (e.g., \u2018x\u2019 vs \u2018y\u2019 aggregations).",
            "Verify backward compatibility with existing tests on other functionality."
        ],
        "context_files": [
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n",
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n"
        ],
        "model_stats": {
            "input_tokens": 2304,
            "output_tokens": 1061,
            "cost": 0.01637
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_aggregation.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_order.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Extend testing in `test_order.py` to include performance benchmarks for the `Perc` class when operating on increasingly large DataFrames. This will help identify potential performance bottlenecks and ensure the percentile calculations scale efficiently.",
        "dynamic_checklist": [
            "Generate increasingly large synthetic DataFrames for performance tests.",
            "Measure and record time taken by `Perc` to compute percentiles at different scales.",
            "Analyze results to identify any potential performance bottlenecks.",
            "Ensure that optimization opportunities are identified without affecting functional correctness."
        ],
        "context_files": [
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n",
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n"
        ],
        "model_stats": {
            "input_tokens": 2304,
            "output_tokens": 1061,
            "cost": 0.01637
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_aggregation.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_order.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Incorporate edge case testing for the `Perc` class, particularly examining its behavior when the DataFrame includes extreme outliers in data. Verify the correctness of percentile calculations and the stability of the results.",
        "dynamic_checklist": [
            "Include outlier data points in datasets for tests.",
            "Check percentile calculations to ensure correct handling of extreme values.",
            "Validate overall class stability when processing datasets with outliers.",
            "Ensure no adverse effects on class performance or other test case results."
        ],
        "context_files": [
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n",
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n"
        ],
        "model_stats": {
            "input_tokens": 2304,
            "output_tokens": 1061,
            "cost": 0.01637
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_aggregation.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_order.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Add functionality to both `Agg` and `Perc` classes to allow specification of a confidence interval for aggregation and percentile calculations. Implement tests to confirm this new feature properly calculates and includes confidence intervals in outputs.",
        "dynamic_checklist": [
            "Extend `Agg` and `Perc` to accept confidence interval parameters.",
            "Develop tests to ensure correct calculation and inclusion of confidence intervals in outputs.",
            "Ensure backward compatibility with existing tests/functions.",
            "Verify the impact of confidence interval specification on the final calculated results."
        ],
        "context_files": [
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n",
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n"
        ],
        "model_stats": {
            "input_tokens": 2304,
            "output_tokens": 1061,
            "cost": 0.01637
        }
    },
    {
        "prompt": "\nYou are a skilled software engineering assistant. You will be provided with multiple files as context. Each file will contain portions of code, documentation, or relevant information about a software system. Your task is to come up with a specific software engineering problem that requires a solution to involve at least two of these files. You will generate a list of these problems, in the generated_problems array response.\n\nFurther, once you have a problem statement, generate a checklist of points to consider and things that should be present in the solution (for example, are the correct Github API calls made if its a function that interfaces with the api). Generate several of these into dynamic_checklist field.\nSome additional guidelines are:\n- Do not output anything other than software engineering problem\n- The problem description should be very detailed and meticulous. It should contain sufficient context such that someone equipped with the codebase and your problem statement will have enough information to implement\n- The problem should be solvable by an autonomous SWE which can do things like installing PyPi packages, but cannot do things like make cloud provider accounts and register for other services manually.\n- The problem should not be overly difficult to implement, and should be fairly easy and not take too many LLM calls. \n- Do not disclose which files would need to be modified to solve the problem.\n\nHere are the files:\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_aggregation.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n\n```\n\nFilename: /Users/alex/workspace/trading-projects/bittensor/taogod/repos/seaborn/tests/_stats/test_order.py\n```python3\n\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n\n```\n\n```",
        "model": "gpt-4o",
        "problem_statement": "Develop tests in `test_aggregation.py` to confirm the efficiency and correctness of aggregation operations when performed over grouped subsets of the DataFrame. Ensure that indices and computed values match expected results for group-specific operations.",
        "dynamic_checklist": [
            "Implement tests to evaluate aggregation over grouped subsets of DataFrame.",
            "Confirm indices and computed values align with expected outcomes for group-specific aggregation.",
            "Check for potential performance issues when handling large or complex grouped operations.",
            "Ensure no disruptions in existing functionality or introduced regressions."
        ],
        "context_files": [
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom pandas.testing import assert_frame_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.aggregation import Agg, Est\n\n\nclass AggregationFixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n\n        n = 30\n        return pd.DataFrame(dict(\n            x=rng.uniform(0, 7, n).round(),\n            y=rng.normal(size=n),\n            color=rng.choice([\"a\", \"b\", \"c\"], n),\n            group=rng.choice([\"x\", \"y\"], n),\n        ))\n\n    def get_groupby(self, df, orient):\n\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestAgg(AggregationFixtures):\n\n    def test_default(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].mean()\n        assert_frame_equal(res, expected)\n\n    def test_default_multi(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Agg()(df, gb, ori, {})\n\n        grp = [\"x\", \"color\", \"group\"]\n        index = pd.MultiIndex.from_product(\n            [sorted(df[\"x\"].unique()), df[\"color\"].unique(), df[\"group\"].unique()],\n            names=[\"x\", \"color\", \"group\"]\n        )\n        expected = (\n            df\n            .groupby(grp)\n            .agg(\"mean\")\n            .reindex(index=index)\n            .dropna()\n            .reset_index()\n            .reindex(columns=df.columns)\n        )\n        assert_frame_equal(res, expected)\n\n    @pytest.mark.parametrize(\"func\", [\"max\", lambda x: float(len(x) % 2)])\n    def test_func(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Agg(func)(df, gb, ori, {})\n\n        expected = df.groupby(\"x\", as_index=False)[\"y\"].agg(func)\n        assert_frame_equal(res, expected)\n\n\nclass TestEst(AggregationFixtures):\n\n    # Note: Most of the underlying code is exercised in tests/test_statistics\n\n    @pytest.mark.parametrize(\"func\", [np.mean, \"mean\"])\n    def test_mean_sd(self, df, func):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(func, \"sd\")(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.mean()\n        err = grouped.std().fillna(0)  # fillna needed only on pinned tests\n        expected = est.assign(ymin=est[\"y\"] - err[\"y\"], ymax=est[\"y\"] + err[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_sd_single_obs(self):\n\n        y = 1.5\n        ori = \"x\"\n        df = pd.DataFrame([{\"x\": \"a\", \"y\": y}])\n        gb = self.get_groupby(df, ori)\n        res = Est(\"mean\", \"sd\")(df, gb, ori, {})\n        expected = df.assign(ymin=y, ymax=y)\n        assert_frame_equal(res, expected)\n\n    def test_median_pi(self, df):\n\n        ori = \"x\"\n        df = df[[\"x\", \"y\"]]\n        gb = self.get_groupby(df, ori)\n        res = Est(\"median\", (\"pi\", 100))(df, gb, ori, {})\n\n        grouped = df.groupby(\"x\", as_index=False)[\"y\"]\n        est = grouped.median()\n        expected = est.assign(ymin=grouped.min()[\"y\"], ymax=grouped.max()[\"y\"])\n        assert_frame_equal(res, expected)\n\n    def test_weighted_mean(self, df, rng):\n\n        weights = rng.uniform(0, 5, len(df))\n        gb = self.get_groupby(df[[\"x\", \"y\"]], \"x\")\n        df = df.assign(weight=weights)\n        res = Est(\"mean\")(df, gb, \"x\", {})\n        for _, res_row in res.iterrows():\n            rows = df[df[\"x\"] == res_row[\"x\"]]\n            expected = np.average(rows[\"y\"], weights=rows[\"weight\"])\n            assert res_row[\"y\"] == expected\n\n    def test_seed(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        args = df, gb, ori, {}\n        res1 = Est(\"mean\", \"ci\", seed=99)(*args)\n        res2 = Est(\"mean\", \"ci\", seed=99)(*args)\n        assert_frame_equal(res1, res2)\n",
            "\nimport numpy as np\nimport pandas as pd\n\nimport pytest\nfrom numpy.testing import assert_array_equal\n\nfrom seaborn._core.groupby import GroupBy\nfrom seaborn._stats.order import Perc\nfrom seaborn.utils import _version_predates\n\n\nclass Fixtures:\n\n    @pytest.fixture\n    def df(self, rng):\n        return pd.DataFrame(dict(x=\"\", y=rng.normal(size=30)))\n\n    def get_groupby(self, df, orient):\n        # TODO note, copied from aggregation\n        other = {\"x\": \"y\", \"y\": \"x\"}[orient]\n        cols = [c for c in df if c != other]\n        return GroupBy(cols)\n\n\nclass TestPerc(Fixtures):\n\n    def test_int_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(3)(df, gb, ori, {})\n        percentiles = [0, 50, 100]\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_list_k(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        percentiles = [0, 20, 100]\n        res = Perc(k=percentiles)(df, gb, ori, {})\n        assert_array_equal(res[\"percentile\"], percentiles)\n        assert_array_equal(res[\"y\"], np.percentile(df[\"y\"], percentiles))\n\n    def test_orientation(self, df):\n\n        df = df.rename(columns={\"x\": \"y\", \"y\": \"x\"})\n        ori = \"y\"\n        gb = self.get_groupby(df, ori)\n        res = Perc(k=3)(df, gb, ori, {})\n        assert_array_equal(res[\"x\"], np.percentile(df[\"x\"], [0, 50, 100]))\n\n    def test_method(self, df):\n\n        ori = \"x\"\n        gb = self.get_groupby(df, ori)\n        method = \"nearest\"\n        res = Perc(k=5, method=method)(df, gb, ori, {})\n        percentiles = [0, 25, 50, 75, 100]\n        if _version_predates(np, \"1.22.0\"):\n            expected = np.percentile(df[\"y\"], percentiles, interpolation=method)\n        else:\n            expected = np.percentile(df[\"y\"], percentiles, method=method)\n        assert_array_equal(res[\"y\"], expected)\n\n    def test_grouped(self, df, rng):\n\n        ori = \"x\"\n        df = df.assign(x=rng.choice([\"a\", \"b\", \"c\"], len(df)))\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        for x, res_x in res.groupby(\"x\"):\n            assert_array_equal(res_x[\"percentile\"], k)\n            expected = np.percentile(df.loc[df[\"x\"] == x, \"y\"], k)\n            assert_array_equal(res_x[\"y\"], expected)\n\n    def test_with_na(self, df):\n\n        ori = \"x\"\n        df.loc[:5, \"y\"] = np.nan\n        gb = self.get_groupby(df, ori)\n        k = [10, 90]\n        res = Perc(k)(df, gb, ori, {})\n        expected = np.percentile(df[\"y\"].dropna(), k)\n        assert_array_equal(res[\"y\"], expected)\n"
        ],
        "model_stats": {
            "input_tokens": 2304,
            "output_tokens": 1061,
            "cost": 0.01637
        }
    }
]